import streamlit as st
import os
import tempfile
####################################################################
# Install
#####################################################################

#print("Fixing numpy conflict...")

# Clear everything and reinstall
import subprocess
import sys

# Force reinstall numpy and mediapipe
#subprocess.run([sys.executable, "-m", "pip", "uninstall", "-y", "numpy", "mediapipe"], capture_output=True)
#subprocess.run([sys.executable, "-m", "pip", "install", "--no-cache-dir", "numpy"], capture_output=True)
#subprocess.run([sys.executable, "-m", "pip", "install", "--no-cache-dir", "mediapipe"], capture_output=True)

#print("✓ Fix complete! Please restart runtime now.")
#print("After restart, run the code below.")

#####################################################################
# Import Libraries
#####################################################################
import time
import cv2
import mediapipe as mp
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.spatial.distance import cosine
from scipy.stats import zscore
from scipy.signal import find_peaks
import json
import os
from datetime import datetime
from typing import List, Dict, Tuple, Optional
#from google.colab import files
#from IPython.display import HTML, Image, display, Javascript
#from google.colab.output import eval_js
from base64 import b64decode, b64encode
import io
from PIL import Image as PILImage
import time
import torch
import torch.nn as nn
import glob
from pathlib import Path
from openai import OpenAI
import random
import seaborn as sns
import pprint
from scipy.interpolate import interp1d
from dotenv import load_dotenv

mp_pose = mp.solutions.pose
random.seed(244)

#####################################################################
# Define Parameters
#####################################################################

load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=openai_api_key)

model_dir = 'C:/Users/User/OneDrive/Desktop/Deepproject/MODEL'

RUNNING_LANDMARKS = {
    'left_shoulder': 11,
    'right_shoulder': 12,
    'left_elbow': 13,
    'right_elbow': 14,
    'left_wrist': 15,
    'right_wrist': 16,
    'left_hip': 23,
    'right_hip': 24,
    'left_knee': 25,
    'right_knee': 26,
    'left_ankle': 27,
    'right_ankle': 28,
    'left_heel': 29,
    'right_heel': 30,
    'left_foot_index': 31,
    'right_foot_index': 32
}

selected_features = [
    'trunk_lean','stride_width', 'center_of_mass_y', 'arm_swing_ratio',
    'leading_elbow_angle', 'trailing_elbow_angle',
    'leading_hip_angle', 'trailing_hip_angle',
    'leading_ankle_x', 'trailing_ankle_x',
    'leading_ankle_y', 'trailing_ankle_y',
    'leading_knee_angle', 'trailing_knee_angle',"trunk_lean"
]

ELITE_BENCHMARK = {'Initial Contact': { 'mean_arm_swing_ratio': 0.6751303770087452,
                       'mean_center_of_mass_y': 0.4324450728776479,
                       'mean_leading_ankle_x': 0.5028020334318206,
                       'mean_leading_ankle_y': 0.6866267468207412,
                       'mean_leading_elbow_angle': 87.01216880064237,
                       'mean_leading_hip_angle': 153.53488413099697,
                       'mean_leading_knee_angle': 120.57022289134235,
                       'mean_stride_width': 0.16025693584598524,
                       'mean_trailing_ankle_x': 0.5085855097105406,
                       'mean_trailing_ankle_y': 0.6699449829105776,
                       'mean_trailing_elbow_angle': 95.9773815478598,
                       'mean_trailing_hip_angle': 146.43628839572386,
                       'mean_trailing_knee_angle': 112.19890670675218,
                       'mean_trunk_lean': 13.883994403686392},
  'Mid Stance': { 'mean_arm_swing_ratio': 0.6538931132129046,
                  'mean_center_of_mass_y': 0.43095298581803454,
                  'mean_leading_ankle_x': 0.4865648404622149,
                  'mean_leading_ankle_y': 0.6815187369325546,
                  'mean_leading_elbow_angle': 85.21946486366454,
                  'mean_leading_hip_angle': 153.7955559684822,
                  'mean_leading_knee_angle': 128.50957933085854,
                  'mean_stride_width': 0.22753450007168444,
                  'mean_trailing_ankle_x': 0.5384739820121974,
                  'mean_trailing_ankle_y': 0.6765064240545035,
                  'mean_trailing_elbow_angle': 101.04573464939222,
                  'mean_trailing_hip_angle': 146.39218892414314,
                  'mean_trailing_knee_angle': 115.88243699221466,
                  'mean_trunk_lean': 29.03803560091716},
  'Swing Phase': { 'mean_arm_swing_ratio': 0.648056221747625,
                   'mean_center_of_mass_y': 0.42899440196415134,
                   'mean_leading_ankle_x': 0.5062090699154138,
                   'mean_leading_ankle_y': 0.6727573383908453,
                   'mean_leading_elbow_angle': 86.8672230319216,
                   'mean_leading_hip_angle': 150.88386663042326,
                   'mean_leading_knee_angle': 123.16153203905318,
                   'mean_stride_width': 0.234316210738967,
                   'mean_trailing_ankle_x': 0.5251652378196127,
                   'mean_trailing_ankle_y': 0.680331535438738,
                   'mean_trailing_elbow_angle': 97.54162593190077,
                   'mean_trailing_hip_angle': 146.89651063700953,
                   'mean_trailing_knee_angle': 122.16435625875499,
                   'mean_trunk_lean': 32.592165035257395},
  'Toe Off': { 'mean_arm_swing_ratio': 0.6610577210729103,
               'mean_center_of_mass_y': 0.4307393322049773,
               'mean_leading_ankle_x': 0.49922107926048565,
               'mean_leading_ankle_y': 0.6782630373689743,
               'mean_leading_elbow_angle': 87.92764156760452,
               'mean_leading_hip_angle': 150.62316597280088,
               'mean_leading_knee_angle': 116.91897531066779,
               'mean_stride_width': 0.19905825297217858,
               'mean_trailing_ankle_x': 0.5066870010363371,
               'mean_trailing_ankle_y': 0.684804009814732,
               'mean_trailing_elbow_angle': 99.99109713029358,
               'mean_trailing_hip_angle': 146.2911113101841,
               'mean_trailing_knee_angle': 115.00935721041486,
               'mean_trunk_lean': 30.761747847899578}}

dict_elite_cyle = {'trunk_lean': [12.763244356502547, 15.11507588795958, 17.46690741941661, 19.8172569607417, 22.161280964564703, 24.487844942738235, 26.096694488147687, 25.995144128344936, 26.103966325180156, 25.58008890712853, 24.734407576786875, 23.860309511524648, 22.927726672115988, 22.507874658928824, 22.080217517606695, 21.665620685715005, 20.834182807188924, 20.62493022791284, 21.171424913031803, 22.18583542098984, 23.181910213571836, 24.20584856237712, 25.222794308998562, 26.572496578779088, 27.917267005905835, 29.265429346584085, 30.598584550571744, 31.919253052942896, 32.28328851928547, 32.20548920363401, 32.12007980946458, 31.746235677216422, 31.153964819956197, 30.560240650842346, 29.971428658494865, 29.37605428232018, 28.76258720214261, 28.584157276840003, 28.411072973270702, 28.766608713600977, 29.165115080038422, 29.743541611414326, 30.859469223161188, 31.969635746284148, 33.08897507559824, 34.2017441652762, 33.98853065250665, 33.18019503205472, 31.512643384566367, 29.836818224213935, 28.77606574322886, 28.33042621153931, 27.881032853115414, 28.653372150426776, 29.81938691462365, 32.46303581070836, 35.12808818481548, 37.77102482519484, 38.745822892529226, 37.853228696893886, 36.9687241214619, 35.68049986834879, 33.944184335640884, 32.6177743230095, 31.255228212632733, 29.93511207461828, 28.62853708326813, 28.72029289828117, 28.78599531276307, 28.877774224108563, 29.049309457174754, 29.930629324781737, 30.85851542276069, 31.23500304751891, 31.604689803302463, 32.32603404063484, 32.66730109448753, 31.87152595486542, 31.03994855791114, 30.19857291850831, 29.37270182487929, 28.565086173270405, 29.701186463838788, 30.76819870624682, 31.351863478468054, 31.95984145650626, 32.73560981892397, 34.03895306562619, 35.79129500096468, 37.268706688490745, 39.08716699230584, 39.4204600889078, 40.14598609746223, 40.01261118378432, 38.68711083921148, 37.232183260670745, 35.78887950945096, 34.346651060925005, 32.910937224496315, 31.475223388067626], 'stride_width': [0.1606489241749048, 0.1626500763355331, 0.16465122849616137, 0.16665679076110776, 0.16875287177156317, 0.17078860520732522, 0.1737571678783406, 0.17786563444586112, 0.18227720444893294, 0.186640277629007, 0.19117385827728897, 0.19545435901416672, 0.2001063345452601, 0.20495498257122857, 0.2094335040999934, 0.21484684929838685, 0.21922548019107843, 0.22262557450196888, 0.2260861302399161, 0.22667047558509265, 0.22782491593057233, 0.2279811888395498, 0.2279431547045294, 0.22859594245969575, 0.2291695845448948, 0.22898822362673554, 0.22876478147824306, 0.22876342804885721, 0.22726159226304354, 0.22699141555250144, 0.22900914055465751, 0.2306475245330144, 0.23087533677900682, 0.23107497422620654, 0.2289645885621282, 0.22615150882966742, 0.22307189252478157, 0.2212555205665077, 0.21977190004974756, 0.2177047067986519, 0.2175906114123009, 0.2177265362870437, 0.21491569680079364, 0.21247747912002032, 0.21149220897571908, 0.21051196643290196, 0.20933014084127813, 0.20735031119411942, 0.20683978087007998, 0.20640946135715102, 0.20549588988150158, 0.20409940779893238, 0.201994732118428, 0.19689918876303114, 0.191945079205727, 0.1864429370705452, 0.18560696634197926, 0.18504831811246095, 0.1851679647316987, 0.18478325356976552, 0.18428248848793183, 0.18495543175791251, 0.18728012260504148, 0.1916419833825394, 0.19768630079607477, 0.20392780219412815, 0.21039775838305555, 0.2126094903973618, 0.21553237460795982, 0.21700686030613656, 0.21905299596956584, 0.22128433760913335, 0.2238595879637382, 0.22575187097633578, 0.2268143705225051, 0.2279853412290866, 0.22913267115513336, 0.23159609902766015, 0.2343779995555905, 0.23735862946733083, 0.24039819039390095, 0.2428869765345346, 0.24382780246636035, 0.24483718679989075, 0.24474899887234874, 0.24490934881559678, 0.24665113063645785, 0.247191917208537, 0.24753649868186975, 0.24514116649578763, 0.2403233316632834, 0.23606536343931547, 0.2312414851690783, 0.22603371349979529, 0.22265423169954857, 0.22222397208251438, 0.22174051015300278, 0.2201130654638614, 0.2185216416771514, 0.21693021789044142], 'center_of_mass_y': [0.4336277893230319, 0.43361371404224575, 0.43359963876145957, 0.43358560749581365, 0.4335718198409285, 0.4335728284135762, 0.4335937410360033, 0.4335911964597876, 0.4336081847417836, 0.4336283828118985, 0.43371529449523993, 0.4336963256176975, 0.43362368888200237, 0.43354795709869476, 0.43345720751088374, 0.4333191599402915, 0.43314646784065647, 0.4329617425324941, 0.4327947234878486, 0.43259469051445376, 0.43238615414700426, 0.43232301787350214, 0.43231000297947064, 0.4322937627511494, 0.43227565305675514, 0.43221584387725653, 0.4319293619322807, 0.43160253616882993, 0.43142132160248176, 0.4312730536031301, 0.43132343125632316, 0.4314153027736328, 0.4315629361626326, 0.43172147297064467, 0.4317888873061748, 0.4318743059547562, 0.4320270654839548, 0.432237915121049, 0.43242737416798116, 0.43254949044011753, 0.4325916353421229, 0.43257201174008425, 0.43266344658736927, 0.4325756219082258, 0.43232762283964293, 0.4322745620537888, 0.4321036694132168, 0.43222021814682565, 0.4323238704128699, 0.43243164680866586, 0.4324811821028741, 0.4324718141101075, 0.4324671712895084, 0.4325315617903164, 0.4325884391676296, 0.43267639045069617, 0.43266796760796894, 0.43263139978669807, 0.4325396976849647, 0.4324019432468246, 0.4323244622945334, 0.4322457984466595, 0.43209822065264286, 0.43190624084039164, 0.43175281201719934, 0.4315721115970551, 0.43139755583355827, 0.4314721632632643, 0.43159703966334007, 0.4317417962788632, 0.431785259320188, 0.43171657578340084, 0.43153251827399836, 0.4312216149094279, 0.430853469957893, 0.4304236252183264, 0.4300092203636362, 0.4297313379115529, 0.42945102573619653, 0.42918585006572085, 0.4290007091564061, 0.42884313145781106, 0.42862313592897516, 0.4283576383148329, 0.4281897743386301, 0.4281082776587569, 0.4283339611639579, 0.42865130233254395, 0.42901094729188416, 0.4293584878186234, 0.4297479426520792, 0.43006550882917766, 0.4304654078187515, 0.4308939316264607, 0.4312243790520863, 0.43144617264999285, 0.4316174462217725, 0.43180780654682055, 0.4319977389684982, 0.43218767139017583], 'arm_swing_ratio': [0.6785457763388427, 0.6777545737613403, 0.6769633711838378, 0.6761894581481405, 0.6748757550955753, 0.678254444697142, 0.6831859819608552, 0.6876779461535246, 0.6938430903708422, 0.6965109368370761, 0.6920102187255494, 0.6879445177406048, 0.6862603583970832, 0.6846086493523, 0.6817279615467186, 0.6771072358527273, 0.6705559001743022, 0.6640923361524509, 0.6573412738426382, 0.6545445453223504, 0.6542433027686949, 0.6562064011340303, 0.6581204535973276, 0.6590580068400823, 0.6575784778158146, 0.6559744149521559, 0.6590151556712813, 0.6615735557256943, 0.6654801988512601, 0.6668044692596369, 0.6654099758890945, 0.6628591069787191, 0.6615820435042163, 0.6595934393224417, 0.6577765918244536, 0.6560169411181959, 0.6555786321011997, 0.6528001041228246, 0.6513926775593063, 0.6521206077197196, 0.6546924368986834, 0.658421561964561, 0.6608096840881688, 0.6614462852813987, 0.6616591303773858, 0.6608348714474424, 0.6628127910352856, 0.6624981453416766, 0.6641182515883679, 0.6657824867091197, 0.6682700156635819, 0.6712980713508029, 0.6733233632139599, 0.6754936921005376, 0.6794473766816334, 0.6823817400608162, 0.683729573320424, 0.6862241186592297, 0.6885008731947106, 0.6915696690280362, 0.6924979791633524, 0.6902442069437134, 0.6857346749359131, 0.6814104651518027, 0.6734837368637696, 0.6648237679558536, 0.6554361391401494, 0.6435113965345172, 0.6321316797645522, 0.6235698638044412, 0.619929872890453, 0.6154128867707365, 0.609787909797954, 0.609638501537781, 0.6090071703146842, 0.6100953137850695, 0.6111750115589031, 0.612207407689953, 0.6155529763797856, 0.6205700230376497, 0.6276499659787055, 0.6377411189486948, 0.6459873442697158, 0.652452536189653, 0.6583682270842546, 0.662784379357471, 0.6680647050024837, 0.6693259475046353, 0.6719880983667512, 0.6781527215915436, 0.6854266164351758, 0.6887186005643577, 0.6899054363619983, 0.693758733015318, 0.6962218770187962, 0.6926273282906976, 0.6845207465638109, 0.6760114248304351, 0.6676717589124269, 0.6593320929944189], 'frame': [135.2442, 135.66454545454545, 136.08489090909092, 136.50523636363636, 136.92558181818183, 137.34592727272727, 137.76627272727274, 138.18661818181818, 138.60696363636364, 138.87676363636365, 139.0963818181818, 139.316, 139.5356181818182, 139.88069090909093, 140.30103636363634, 140.7213818181818, 141.14172727272728, 141.56207272727272, 141.9824181818182, 142.2218303030303, 142.4141393939394, 142.41803636363636, 142.42193333333333, 142.4258303030303, 142.42972727272726, 142.32889696969698, 141.91388484848483, 141.49887272727273, 141.26479393939394, 141.08307878787878, 141.33856363636366, 141.75890909090907, 142.17925454545454, 142.5996, 143.01994545454545, 143.44029090909092, 143.86063636363636, 144.2809818181818, 144.70132727272727, 145.12167272727274, 145.54201818181818, 145.96236363636365, 146.3827090909091, 146.57963636363635, 146.609, 146.55245454545454, 146.50987272727272, 146.8443090909091, 147.17874545454546, 147.5131818181818, 147.84761818181818, 148.18205454545455, 148.51649090909092, 148.85092727272726, 149.18536363636366, 149.5198, 149.94014545454547, 150.3604909090909, 150.73316363636363, 150.9628181818182, 151.19247272727273, 151.24130909090908, 150.35116363636365, 148.70787272727273, 147.0645818181818, 146.75529090909092, 146.814, 146.59465454545455, 146.37530909090907, 146.15596363636365, 145.93661818181818, 145.71727272727273, 145.66854545454547, 145.9098181818182, 146.33016363636364, 146.7505090909091, 147.17085454545455, 147.5912, 148.01154545454546, 148.43189090909092, 148.6313393939394, 148.77556363636364, 148.1944545454545, 146.79734545454542, 145.40023636363637, 144.8344606060606, 144.76868484848484, 144.7029090909091, 144.01959999999997, 142.7852545454545, 141.71836363636362, 140.78007878787878, 139.8417939393939, 138.90350909090907, 138.75117575757577, 138.76726060606063, 138.78334545454547, 138.7994303030303, 138.81551515151517, 138.8316], 'time': [4.582977931034483, 4.597115339602926, 4.611252748171369, 4.625390156739812, 4.639527565308255, 4.653664973876698, 4.667802382445141, 4.681939791013584, 4.696077199582027, 4.7051964263322885, 4.712642925809822, 4.720089425287356, 4.72753592476489, 4.739164242424242, 4.753301650992686, 4.767439059561129, 4.781576468129572, 4.795713876698015, 4.809851285266458, 4.81795758272379, 4.8244937791710205, 4.824749571577847, 4.825005363984674, 4.825261156391502, 4.825516948798328, 4.822281832114246, 4.808573988157437, 4.794866144200627, 4.7871894113549285, 4.781258133054685, 4.789900188087775, 4.804037596656218, 4.818175005224661, 4.832312413793104, 4.846449822361547, 4.86058723092999, 4.874724639498433, 4.888862048066876, 4.902999456635318, 4.917136865203762, 4.931274273772205, 4.945411682340648, 4.959549090909091, 4.966239226750261, 4.967343908045978, 4.965584952978056, 4.964291452455591, 4.975565224660397, 4.986838996865203, 4.998112769070011, 5.009386541274817, 5.020660313479624, 5.031934085684431, 5.043207857889238, 5.054481630094044, 5.0657554022988505, 5.079892810867294, 5.094030219435737, 5.106578537095088, 5.114359582027168, 5.122140626959247, 5.123894399164054, 5.094348777429467, 5.039698307210031, 4.985047836990596, 4.974864033437827, 4.976946896551724, 4.969761274817137, 4.962575653082549, 4.955390031347962, 4.948204409613375, 4.941018787878789, 4.939520438871473, 4.947688756530826, 4.961826165099269, 4.975963573667712, 4.990100982236155, 5.004238390804598, 5.018375799373041, 5.032513207941484, 5.039287384186695, 5.044220752351097, 5.024976342737721, 4.978531933124347, 4.932087523510972, 4.913354225008708, 4.91128759317311, 4.909220961337513, 4.885860076628352, 4.843744144897248, 4.807210031347962, 4.7749627864855455, 4.742715541623127, 4.710468296760711, 4.705322828282829, 4.705984883315918, 4.7066469383490075, 4.707308993382097, 4.707971048415187, 4.7086331034482765], 'cycle_progress': [0.0, 1.0101010101010102, 2.0202020202020203, 3.0303030303030303, 4.040404040404041, 5.050505050505052, 6.0606060606060606, 7.070707070707072, 8.080808080808081, 9.090909090909092, 10.101010101010104, 11.111111111111112, 12.121212121212121, 13.131313131313133, 14.141414141414145, 15.151515151515152, 16.161616161616163, 17.171717171717177, 18.181818181818183, 19.191919191919194, 20.202020202020208, 21.21212121212121, 22.222222222222225, 23.232323232323235, 24.242424242424242, 25.252525252525256, 26.262626262626267, 27.272727272727277, 28.28282828282829, 29.292929292929294, 30.303030303030305, 31.31313131313132, 32.323232323232325, 33.33333333333334, 34.34343434343435, 35.353535353535364, 36.36363636363637, 37.37373737373738, 38.38383838383839, 39.3939393939394, 40.404040404040416, 41.41414141414142, 42.42424242424242, 43.43434343434344, 44.44444444444445, 45.45454545454546, 46.46464646464647, 47.47474747474748, 48.484848484848484, 49.494949494949495, 50.50505050505051, 51.51515151515152, 52.52525252525253, 53.53535353535354, 54.545454545454554, 55.555555555555564, 56.56565656565658, 57.57575757575758, 58.58585858585859, 59.5959595959596, 60.60606060606061, 61.61616161616163, 62.62626262626264, 63.63636363636365, 64.64646464646465, 65.65656565656565, 66.66666666666669, 67.67676767676768, 68.6868686868687, 69.6969696969697, 70.70707070707073, 71.71717171717174, 72.72727272727273, 73.73737373737374, 74.74747474747475, 75.75757575757576, 76.76767676767678, 77.77777777777779, 78.7878787878788, 79.7979797979798, 80.80808080808082, 81.81818181818183, 82.82828282828284, 83.83838383838385, 84.84848484848484, 85.85858585858587, 86.86868686868688, 87.87878787878789, 88.8888888888889, 89.89898989898992, 90.90909090909092, 91.91919191919193, 92.92929292929294, 93.93939393939395, 94.94949494949496, 95.95959595959597, 96.96969696969697, 97.979797979798, 98.98989898989899, 100.0], 'leading_elbow_angle': [87.91152970830873, 88.38277771577809, 88.85402572324746, 89.31318158224265, 89.68085283434434, 90.27076495108442, 90.92121022557697, 91.20137749101109, 91.31605597970325, 91.12685509553168, 91.04809153168314, 90.83693981411714, 90.62357756214011, 90.5888496053601, 90.28228885422291, 90.25954286331942, 90.27056149755813, 90.05155533619374, 89.83393858832385, 89.42082747997178, 89.02149112677849, 88.69376374013696, 88.0944198844162, 87.59681904218074, 87.09031011693604, 86.57103538067177, 86.10277844371352, 85.9637222145761, 85.81241584024076, 85.655310439252, 85.34280602350817, 84.86063782086717, 84.54372760148348, 84.35566983677393, 84.60023100799032, 84.90576348551608, 85.02295662848505, 85.42344579151919, 85.87599273556985, 86.31237275695221, 86.77463032289576, 87.28777565010051, 87.64463668978104, 87.74491320917897, 87.67753011439994, 87.40728598990461, 86.99978973994398, 86.63524351030979, 86.44315456540265, 86.31573332699382, 86.2390288252576, 86.20207980038757, 86.1653232901324, 86.33407615287842, 86.68711064478732, 87.10265058509879, 87.45908409230427, 87.80759038884459, 88.00259930866798, 87.88915327330899, 87.73464064717737, 87.67933632453183, 87.42248428153222, 87.28107189445427, 87.68295660073748, 87.79721383498736, 87.78046859458186, 87.76005608017128, 87.72644361549482, 87.95746520704964, 88.21499632108875, 88.56264534303648, 88.95537532667886, 88.44999892549227, 87.46873147340821, 86.68189710445085, 85.92361953889225, 84.87064738022113, 84.18327767893118, 83.46619798742549, 83.23234670084751, 83.41362864167688, 83.83820146233379, 84.32477772918949, 84.57598834261576, 84.98129723871675, 85.30529177336585, 85.44297893846439, 85.76771102641735, 86.47884694870703, 87.26412945589979, 88.05824710519123, 88.7593609278187, 89.49411963772108, 89.97894243852019, 90.20434607321086, 90.22979553783152, 90.20309899134243, 90.14618986554026, 90.08928073973809], 'trailing_elbow_angle': [95.71342760056372, 96.66787449582891, 97.62232139109412, 98.5647532649764, 99.48646098484241, 100.48739913454409, 101.70753495892029, 102.71879187105868, 103.39974127592612, 103.70909458345025, 103.47457892789993, 103.59086483082942, 102.55532515559288, 101.28933845841065, 100.38516015635888, 99.22014873467562, 98.2016968234504, 98.0870831303659, 98.78862219691908, 99.79734819104054, 100.96516368318945, 101.72189643158721, 102.16739672271542, 102.54783283909799, 102.5602675179094, 102.17129901419004, 101.48431338732745, 100.8779957854047, 100.45359569219234, 100.04502322377479, 99.74245659794613, 99.59075746927651, 99.51954835258829, 99.3957137060673, 100.31143875126504, 101.25039135607605, 102.01093689470103, 102.71291619872451, 103.22558775004904, 103.66094516232369, 103.85096829557327, 104.04084038457717, 104.1615806604299, 104.19274257855473, 104.35751581184834, 104.7263619074312, 105.52369313957456, 106.10860776291206, 106.50628860125451, 106.90139227092138, 107.01054525671825, 106.83385354620994, 106.65580564722659, 106.59434606849388, 106.19642284021089, 105.0591749655285, 104.7044744923804, 104.4076402751312, 103.93907519406724, 103.34223436581331, 102.35739084165776, 101.25459117873933, 100.67277782264138, 100.49198847996962, 100.0811457530335, 100.12823211283461, 100.10992660905247, 99.3890981692535, 98.5332906069972, 97.70558898874468, 96.89157437619875, 95.74667326879624, 94.24164288228611, 94.21209547110661, 94.71005381113274, 94.88052415095228, 94.95560972046043, 95.26263312690855, 95.60534071628074, 96.01990693844198, 96.4061590816506, 96.85259784748165, 97.5326045360744, 98.27940084133397, 98.4512554498793, 98.44295118824877, 98.25228210383261, 98.31240126353543, 98.23653472155452, 98.25786164958895, 98.28328360662681, 98.6411720484714, 99.05302142670563, 99.3995240963842, 99.81352532769449, 99.9317591455368, 100.14631519667024, 100.25799973731965, 100.37238686723562, 100.48677399715157], 'leading_hip_angle': [153.6650809807139, 153.42772176204696, 153.19036254338005, 152.96133653146717, 152.73496559305946, 152.547323536721, 152.36698855305806, 152.03745587803687, 151.72751727297737, 151.3189205021707, 150.87423909961515, 150.5963976853901, 150.66617420484155, 150.88958689761353, 150.95216326099336, 150.7390548357426, 150.55329010978738, 150.54252299713005, 150.69498647046083, 151.00085831179004, 151.45501293333177, 152.00791308897942, 152.45098427665394, 152.99578090191093, 153.34942367947448, 153.6192383299973, 153.7833505087826, 154.04414278647698, 154.23065523939414, 154.39047091956908, 154.28295306205064, 154.226730372284, 154.21073779673895, 154.17935532427683, 154.30158652373623, 154.4552507186364, 154.82500383052806, 155.1171534965329, 155.27162189389608, 155.22540577756556, 154.95203382923003, 154.62181307037216, 154.34863221518575, 153.9903063144944, 153.5441119138624, 153.18167282833323, 152.9149705814385, 152.42705737961538, 151.9942994599731, 151.60673642478446, 151.42326830996805, 151.44126894948317, 151.477738414478, 151.62897322886212, 151.73343666259257, 151.76418344119813, 151.87517756904538, 151.97773850943727, 152.00700034697348, 151.89588334547597, 151.7122817122109, 151.4602521636447, 151.14559828419848, 150.92046341303399, 150.6627323862544, 150.1982978676211, 149.74576450504088, 149.2691724251439, 148.95053748292605, 148.75155184052704, 148.78219983661413, 148.89251639277109, 148.9478091342826, 149.24860912694226, 149.5537319659108, 149.687029711167, 149.77021562110127, 149.8262291357944, 150.03558083414254, 150.1728290754391, 150.3199374973655, 150.8468665769738, 151.32960207072466, 151.7043555194704, 151.43071815182125, 151.0457929368148, 150.71388457538058, 150.76333507365823, 150.77812314541106, 151.11724381489475, 151.38562695627658, 151.65694629020766, 151.6599538205584, 151.66796627339932, 151.64237975730066, 151.32621854602314, 150.97049188694686, 150.71987221465372, 150.5280986643206, 150.33632511398747], 'trailing_hip_angle': [146.73968657084032, 146.907576415981, 147.0754662611217, 147.24814939300433, 147.4418343541341, 147.61243647848823, 147.75221035014917, 147.82097066517545, 147.82405607536649, 147.90195103430307, 148.07157945451218, 148.00571460856094, 147.66560487324085, 147.2030779815963, 146.6739610668431, 146.2042871555072, 145.91374007719455, 145.74415704319688, 145.71152416283266, 145.82390953132102, 146.06620417142588, 146.36842599829603, 146.58450339916502, 146.82632308388395, 146.87230216875216, 146.78484443073353, 146.68322683795233, 146.40151918858948, 146.3272879904697, 146.28863684419008, 146.23422321966913, 146.14195998421528, 146.11407146784424, 146.12169675609402, 146.50662665519752, 146.88285966180857, 146.89862581267425, 146.43509114348183, 145.94564781490882, 145.41564490978982, 144.9356283118856, 144.63510345501567, 144.5826179546813, 144.47125137681064, 144.35551242886166, 144.2251627495119, 144.4674396065312, 144.82142391163654, 145.226981939078, 145.65833178568192, 145.88829594781024, 145.9151031232619, 145.9549475515915, 146.14748569440528, 146.37602442799928, 146.62698869793533, 146.7237928772425, 146.62795513827064, 146.30889267636533, 146.07919825096752, 145.9339476955503, 145.94121102666602, 146.10363019928988, 146.52777419513703, 146.77970144409056, 147.02177758463867, 147.1842725720833, 147.4396721439159, 147.52230149619217, 147.62956507301456, 147.79515185526145, 148.11522949291177, 148.35474105347512, 148.75362716647956, 149.04170375265193, 149.15675956771494, 149.33838349118994, 149.3524036513743, 149.0461057777681, 148.3730434687388, 147.91802597491372, 147.47787785073888, 147.09571448348174, 146.86496069083282, 146.94971628504325, 147.16020658072568, 147.15834566865598, 147.08556279522463, 146.9755236617453, 146.6486229278857, 146.3999911737704, 146.02249324858235, 145.98934274220895, 145.92413327352065, 146.0081066780808, 146.20413767339096, 146.42631292994082, 146.64615516701082, 146.8253561317275, 147.00455709644413], 'leading_ankle_x': [0.5040315740764141, 0.503629015093786, 0.5032264561111578, 0.502823894383826, 0.5024317383367003, 0.5017528269804938, 0.49982010955106126, 0.4972263528813768, 0.49432204571667343, 0.492011355562034, 0.49121021017752065, 0.4894370846898191, 0.4880783811179752, 0.487329600118349, 0.48693649264454386, 0.4859304527860022, 0.48600664585435177, 0.4859184246661612, 0.4855525451566008, 0.4861251106068266, 0.48636882307150897, 0.48738998506992603, 0.4888958370307253, 0.4907343441755708, 0.4911643423378242, 0.49200235496602884, 0.4923483232560633, 0.4911145783394575, 0.48891006611635285, 0.48710530861465623, 0.4856975829108646, 0.48592168880156195, 0.48708198220225596, 0.4882508516694109, 0.48847486995705447, 0.4888616029531216, 0.4885983654620973, 0.48774716839334276, 0.48738729203460796, 0.4885793579360301, 0.4885511053505871, 0.48814997123908815, 0.4897771007023074, 0.4905176377465779, 0.49026742355459263, 0.48942592874562196, 0.4890343743787119, 0.48838186776479986, 0.48725510007165596, 0.48619608099292017, 0.48495711492710186, 0.4835475280536621, 0.4828055182838004, 0.4853581565270897, 0.4887347038295459, 0.4928314992766413, 0.4959825587432117, 0.4986817615324123, 0.4999287572047325, 0.5015475851634085, 0.5035108284136562, 0.5053293140031924, 0.506381044436344, 0.5060740002563054, 0.5054398686396955, 0.5042379847896069, 0.5029713802208503, 0.503311867614241, 0.5033538671824065, 0.5046598299315933, 0.5058415311362106, 0.5078926576999553, 0.5100085282469338, 0.5138917963536099, 0.5171687778618902, 0.5209499368002695, 0.5227652521440251, 0.522776960321847, 0.5209362229904216, 0.5177175831095663, 0.5143924544365343, 0.5125496988946063, 0.5099796001461946, 0.5083614891916213, 0.5086267088561798, 0.5089209657943912, 0.5083418771534405, 0.5080372658435593, 0.5078071922567156, 0.5074059706581512, 0.5060629227261652, 0.5043654784253752, 0.5048685739771586, 0.5057675461776329, 0.5078394428984385, 0.5105912718281752, 0.514010950593831, 0.5169426527181811, 0.5199254198503765, 0.5229081869825721], 'trailing_ankle_x': [0.5114162635117769, 0.5101784251799788, 0.5089405868481808, 0.5076983356673609, 0.5064319516181043, 0.5050821685508796, 0.504303088841068, 0.5042660360826536, 0.5048609347889068, 0.5052073407325556, 0.5056440953538348, 0.5063158635473086, 0.5084867274938886, 0.5106535166375339, 0.5122819042214616, 0.5151975578598678, 0.5171702042120048, 0.5192873093530348, 0.521478025961498, 0.5234774340377575, 0.526163190336499, 0.5280004548500095, 0.5293672688664247, 0.5310244369956242, 0.533111967638214, 0.5342023333200526, 0.534983631760153, 0.5374543015356091, 0.5389199514930748, 0.5411722701465015, 0.543468798961242, 0.5443012107105192, 0.5439421931089626, 0.543575042321533, 0.5419593869667838, 0.5398842549526406, 0.5383250859106806, 0.5383573606230018, 0.5385092059698445, 0.5376432038307416, 0.5374473474819025, 0.5370253660379861, 0.5351440270229271, 0.5354400479742373, 0.5376958906499877, 0.5396805322297595, 0.5419081301478275, 0.5444677361642472, 0.54501663486944, 0.5451368180206779, 0.5453584654077888, 0.5456912445660342, 0.5454454789131127, 0.5424574934572433, 0.5384396743824535, 0.5320874418008659, 0.5263809324517544, 0.5218090472969593, 0.5193688386657472, 0.5164266348444602, 0.5132353859231779, 0.510171805832377, 0.5071346167789114, 0.5054151441402056, 0.5056234045642946, 0.5054179691253438, 0.5051438236777981, 0.5058684999110572, 0.5069612444582763, 0.5069972184472463, 0.5073737034734602, 0.5069470681268609, 0.5065856107789007, 0.5062992072289415, 0.5069880061740225, 0.5075825375150325, 0.5092156492834139, 0.5121808045202659, 0.5167040314768752, 0.521701212979936, 0.5269458859135105, 0.53037677561932, 0.5324626589688689, 0.534305155742206, 0.5344194920558369, 0.5342469039666458, 0.5344503224806955, 0.5349633472186823, 0.535226495151884, 0.5342743575284502, 0.5338141108363866, 0.5338915940357278, 0.530877462740709, 0.5274509391671781, 0.525724177245269, 0.5236852462567163, 0.5205813169447762, 0.5178493457110542, 0.5152618141413638, 0.5126742825716734], 'leading_ankle_y': [0.6878072591781617, 0.6886049293609581, 0.6894025995437545, 0.6902001482428927, 0.6909963154144961, 0.6918214982509613, 0.6929077223196174, 0.693156262101549, 0.6935102130776705, 0.6934447642217983, 0.6929479547778765, 0.6921724949147966, 0.6920274433251583, 0.6914179644109023, 0.6908536298129294, 0.6903978810462085, 0.6901707538442178, 0.6899176618250934, 0.689912616509741, 0.6894908227984351, 0.689259056252783, 0.6887939055710128, 0.6883362946748733, 0.6875781842761569, 0.6867865754441781, 0.6858853313875921, 0.6850750687284902, 0.6841579963423989, 0.6833878666467137, 0.6825386989682611, 0.6818542936075818, 0.6811442743681898, 0.6799648115666226, 0.6786014378031094, 0.6779418924608617, 0.677667183655681, 0.6780628547798504, 0.6788742171005768, 0.6803492629266749, 0.6814990841363415, 0.6820736791758826, 0.6824406183950829, 0.6826273868752248, 0.6821803060667683, 0.6816129979636933, 0.6814485829916868, 0.6805227356149692, 0.6794741632326685, 0.6784310168840668, 0.6774381715131529, 0.6763895069631664, 0.6752833891630172, 0.674218320294462, 0.673511603314106, 0.6737428953690963, 0.6748309831248389, 0.6761779409454327, 0.6781372033444317, 0.6799309242008913, 0.681553850350958, 0.6831431276527318, 0.683352534785656, 0.6825297132024861, 0.6815111273223703, 0.680106845551669, 0.6790379128843846, 0.6782441304485003, 0.6777743973686238, 0.6774774634974171, 0.6769024141492266, 0.6762542224454158, 0.6757707947451659, 0.6751668947675011, 0.6745447904771025, 0.674208418814582, 0.674456244470134, 0.6747428520772192, 0.6749277606023683, 0.6750771588932385, 0.6747258034281056, 0.6742962494060246, 0.674376592172276, 0.6750842031463228, 0.6753502350645836, 0.6752481523336786, 0.6753491087460759, 0.6758842485273727, 0.6765232794700247, 0.6772571144580841, 0.6769259674157759, 0.6761588264270263, 0.6750818016340033, 0.6740180530676938, 0.6737942558443908, 0.6742337704161201, 0.6740068345777916, 0.674923835640965, 0.6759599904236168, 0.6769773772208377, 0.6779947640180588], 'trailing_ankle_y': [0.6713449724793434, 0.672248719847684, 0.6731524672160245, 0.6740582806244041, 0.674970188813017, 0.6757962450200861, 0.6764805736520074, 0.6775656963012435, 0.678388513889698, 0.6790331720579754, 0.6800842746521487, 0.6809514919135305, 0.680433449680155, 0.6804432820436931, 0.6806437355925338, 0.6803237512169462, 0.6794612597899004, 0.6784098317959092, 0.6770305557240139, 0.6755100267469281, 0.674218087258363, 0.6737230330239643, 0.6740580144776239, 0.6746075946827127, 0.6756399897264711, 0.67672802116907, 0.6773661557745452, 0.6769805325594815, 0.6767224464947527, 0.6765331907303647, 0.6762266072732029, 0.6760648549464013, 0.6769706106931273, 0.6781667058547337, 0.6793964782384911, 0.6804248585079655, 0.6812411022229629, 0.6823841944419976, 0.683113844701136, 0.683745102521145, 0.6847012457822309, 0.6858118705001744, 0.6866980219750694, 0.6871425139619846, 0.6873941310074594, 0.6873055854298852, 0.6867999990795598, 0.6866187828965862, 0.685760774299954, 0.6848144818644332, 0.6846049866664289, 0.685136922919389, 0.6856841113784097, 0.6867853898300066, 0.6878008381865242, 0.6886835808144675, 0.6886189800462337, 0.6880536516886768, 0.687253731628259, 0.6859688066539138, 0.6846032209277153, 0.6843835579183366, 0.6847586986250348, 0.6850893171472984, 0.6855336480787306, 0.6859366543836064, 0.6861664346496265, 0.6859805865826029, 0.685691857975059, 0.6862249594695641, 0.6865623390580669, 0.6864652334745484, 0.6864592817360704, 0.6860561345879478, 0.6853196920982515, 0.6841559236569837, 0.6835317685661894, 0.6834336733314726, 0.6828192259058807, 0.6828482821781225, 0.6831526399996546, 0.6830877052220431, 0.682129352638577, 0.6810721286322131, 0.6803241116451494, 0.6794290938435179, 0.6783340338483, 0.6767226923090038, 0.6750174868954553, 0.6747449520282071, 0.6753098879608241, 0.6764194706732576, 0.6776600817879042, 0.678538141923601, 0.6787359851703499, 0.6795530046684574, 0.6793798306374839, 0.6792881362719969, 0.6792609479806639, 0.6792337596893311], 'leading_knee_angle': [120.22549062632622, 120.42090796781196, 120.61632530929768, 120.8308751012106, 121.06369064040186, 121.28998611295232, 121.62703965571406, 121.30504737073784, 121.08420317808185, 120.61459257219602, 120.37970941770864, 120.53749005728781, 121.7581138481086, 123.04125150941832, 124.39117104863469, 125.53030625480795, 126.36512799189246, 126.8079661491189, 127.3387986022135, 127.4467712394607, 127.73023357569895, 127.55560120142876, 127.80548671394025, 127.97320653904065, 128.20710018183314, 128.40215485183901, 128.7372990601078, 129.0524615494516, 128.83832687365887, 128.626364719027, 128.58089064474612, 128.4969784617483, 128.34809200614055, 128.0533123089432, 127.2915436915912, 126.66663015155969, 126.57447158488102, 126.97205803296009, 127.48390924005636, 127.7733774507049, 127.89453816657658, 127.84603286793721, 127.29070566968187, 126.51094633573999, 126.0322472787474, 125.51097910663415, 124.91072990059007, 124.05405229323013, 123.29300467241079, 122.53036115473395, 121.94395723249845, 121.53345680810148, 121.1156814260263, 120.77064272805208, 120.81544477566867, 120.55547730147983, 120.6052285921053, 120.89003471271619, 121.09648088240586, 121.01770012991138, 120.69584064835047, 119.69037419257998, 118.15182451492329, 116.60853078813476, 115.50402219839945, 114.91202916358304, 114.5289874563045, 114.76995004824532, 115.0885663522694, 115.01392363370486, 115.47180596867807, 115.817908449141, 116.20849238947008, 117.22351059116437, 118.51274824205714, 119.9982467825301, 121.38571924766079, 122.7862858952038, 124.23607974464072, 125.02279202285631, 125.39109013785095, 126.36199003610906, 127.02217864811176, 127.48085399630722, 127.05178300150875, 126.54090985429352, 126.50737985863316, 126.72946447184982, 127.1651181742276, 126.25108335180245, 124.61323387368887, 123.05082414689683, 121.79594141241074, 121.16257771752674, 120.99318275773386, 120.639971154225, 120.78130172455444, 121.00415900206384, 121.28070213396221, 121.55724526586057], 'trailing_knee_angle': [112.19608649209702, 112.30353420430843, 112.41098191651986, 112.52136088946278, 112.64411557754003, 112.79935585758278, 113.26646445358058, 113.99145501605598, 114.59420097241464, 115.02772485656047, 115.99184726354824, 116.49262398317644, 116.20462422666242, 116.30153643726132, 116.46154557971268, 116.47342888504404, 116.23761562900641, 116.1543806915983, 116.02026094111935, 115.39142222234096, 114.93070425936689, 114.55446584149017, 114.6560885070972, 114.99029323772015, 115.57633657026106, 116.13271662230154, 116.48248090535836, 115.93479463549717, 115.4255329572937, 115.0540120959213, 114.64740554679206, 114.40305019386808, 114.4992446408903, 114.7824623788526, 115.4006576375071, 115.81244471983148, 115.9510596645748, 116.08626663732367, 116.08676584499355, 115.88534086809442, 116.16761405228998, 116.78879928406337, 117.06068937301316, 117.24720072018408, 117.5491478088885, 117.57592584752645, 117.83528782589624, 118.1645018137668, 118.31116089550771, 118.46579221080654, 118.64454949908597, 118.84894305323223, 119.05256877868122, 119.58163906215766, 120.07467085909762, 120.1048184745385, 119.88879057000378, 118.86136347958636, 117.17377237102971, 115.20314772860375, 113.37505912410847, 112.40730890403879, 112.80723226545139, 113.95775964731983, 115.11684321201307, 116.1057535938105, 116.96821920868834, 117.56741658358841, 118.10188084009972, 118.74076589312975, 119.4393501356108, 120.26523932803606, 121.04145763550794, 122.04014828627706, 122.70091784238869, 122.99665579061981, 123.56261321914705, 124.2912217773904, 124.71356709403973, 125.27071498910922, 125.8222362004031, 126.0820576243497, 125.56192621101853, 125.08395307801484, 125.05313204560761, 124.87546759318109, 123.9752280153223, 122.60944527824898, 121.29943787575816, 120.24894215805357, 119.86537553408148, 120.0053179884772, 120.11283187034742, 119.86153349012831, 119.25651164826536, 119.55353867640414, 119.4801796108915, 119.30331521304164, 119.1207745490589, 118.93823388507613]}

#####################################################################
# Posture Function
#####################################################################

# --- Angle Calculation ---
def calculate_angle(a, b, c):
    ba = a - b
    bc = c - b
    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-8)
    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))
    return np.degrees(angle)

# --- Pose Feature Extraction ---
def extract_pose_features(landmarks):
    features = {}
    pose_array = np.array([[lm.x, lm.y, lm.z] for lm in landmarks.landmark])

    features['left_ankle_x'] = pose_array[RUNNING_LANDMARKS['left_ankle']][0]
    features['left_ankle_y'] = pose_array[RUNNING_LANDMARKS['left_ankle']][1]
    features['right_ankle_x'] = pose_array[RUNNING_LANDMARKS['right_ankle']][0]
    features['right_ankle_y'] = pose_array[RUNNING_LANDMARKS['right_ankle']][1]

    features['left_knee_angle'] = calculate_angle(
        pose_array[RUNNING_LANDMARKS['left_hip']][:2],
        pose_array[RUNNING_LANDMARKS['left_knee']][:2],
        pose_array[RUNNING_LANDMARKS['left_ankle']][:2]
    )
    features['right_knee_angle'] = calculate_angle(
        pose_array[RUNNING_LANDMARKS['right_hip']][:2],
        pose_array[RUNNING_LANDMARKS['right_knee']][:2],
        pose_array[RUNNING_LANDMARKS['right_ankle']][:2]
    )
    features['left_elbow_angle'] = calculate_angle(
        pose_array[RUNNING_LANDMARKS['left_shoulder']][:2],
        pose_array[RUNNING_LANDMARKS['left_elbow']][:2],
        pose_array[RUNNING_LANDMARKS['left_wrist']][:2]
    )
    features['right_elbow_angle'] = calculate_angle(
        pose_array[RUNNING_LANDMARKS['right_shoulder']][:2],
        pose_array[RUNNING_LANDMARKS['right_elbow']][:2],
        pose_array[RUNNING_LANDMARKS['right_wrist']][:2]
    )
    features['left_hip_angle'] = calculate_angle(
        pose_array[RUNNING_LANDMARKS['left_shoulder']][:2],
        pose_array[RUNNING_LANDMARKS['left_hip']][:2],
        pose_array[RUNNING_LANDMARKS['left_knee']][:2]
    )
    features['right_hip_angle'] = calculate_angle(
        pose_array[RUNNING_LANDMARKS['right_shoulder']][:2],
        pose_array[RUNNING_LANDMARKS['right_hip']][:2],
        pose_array[RUNNING_LANDMARKS['right_knee']][:2]
    )

    shoulder_center = (pose_array[RUNNING_LANDMARKS['left_shoulder']] + pose_array[RUNNING_LANDMARKS['right_shoulder']]) / 2
    hip_center = (pose_array[RUNNING_LANDMARKS['left_hip']] + pose_array[RUNNING_LANDMARKS['right_hip']]) / 2
    trunk_vector = shoulder_center - hip_center
    features['trunk_lean'] = np.degrees(np.arctan2(trunk_vector[0], trunk_vector[1]))

    features['stride_width'] = abs(
        pose_array[RUNNING_LANDMARKS['left_ankle']][0] - pose_array[RUNNING_LANDMARKS['right_ankle']][0]
    )
    features['center_of_mass_y'] = (hip_center[1] + shoulder_center[1]) / 2

    left_arm_swing = np.linalg.norm(pose_array[RUNNING_LANDMARKS['left_wrist']] - pose_array[RUNNING_LANDMARKS['left_shoulder']])
    right_arm_swing = np.linalg.norm(pose_array[RUNNING_LANDMARKS['right_wrist']] - pose_array[RUNNING_LANDMARKS['right_shoulder']])
    features['arm_swing_ratio'] = min(left_arm_swing, right_arm_swing) / max(left_arm_swing, right_arm_swing)

    return features

#####################################################################
# Cycle Function
#####################################################################

def detect_gait_cycles(pose_data):
    left_ankle_y = pose_data['left_ankle_y'].values
    right_ankle_y = pose_data['right_ankle_y'].values

    left_strikes, _ = find_peaks(-left_ankle_y, distance=10, prominence=0.02)
    right_strikes, _ = find_peaks(-right_ankle_y, distance=10, prominence=0.02)

    gait_cycles = []
    for i in range(len(left_strikes) - 1):
        gait_cycles.append({
            'start_frame': left_strikes[i],
            'end_frame': left_strikes[i + 1],
            'foot': 'left',
            'duration_frames': left_strikes[i + 1] - left_strikes[i]
        })

    for i in range(len(right_strikes) - 1):
        gait_cycles.append({
            'start_frame': right_strikes[i],
            'end_frame': right_strikes[i + 1],
            'foot': 'right',
            'duration_frames': right_strikes[i + 1] - right_strikes[i]
        })

    return gait_cycles, left_strikes, right_strikes

def extract_single_gait_cycle(pose_data, cycle_info):
    start = cycle_info['start_frame']
    end = cycle_info['end_frame']
    cycle_data = pose_data.iloc[start:end].copy()
    cycle_data['cycle_progress'] = np.linspace(0, 100, len(cycle_data))
    return cycle_data

def normalize_gait_cycle(cycle_df, num_points=100):
    if len(cycle_df) < 2:
        return pd.DataFrame()  # ไม่สามารถ interpolate ได้

    x_old = np.linspace(0, 1, len(cycle_df))
    x_new = np.linspace(0, 1, num_points)
    interpolated = {}

    for col in cycle_df.columns:
        if cycle_df[col].dtype in [np.float32, np.float64, np.int64, np.int32]:
            interpolated[col] = np.interp(x_new, x_old, cycle_df[col])

    return pd.DataFrame(interpolated)

def aggregate_normalized_cycles(labeled_pose_data, gait_cycles):
    all_cycles = []

    for cycle in gait_cycles:
        cycle_data = extract_single_gait_cycle(labeled_pose_data, cycle)
        normalized = normalize_gait_cycle(cycle_data)
        all_cycles.append(normalized)

    combined_df = pd.concat(all_cycles)
    median_cycle = combined_df.groupby(combined_df.index).median()

    return median_cycle

def process_video(video_path, sample_rate=3):
    """Process video and extract pose data"""
    print(f"Processing video: {video_path}")

    cap = cv2.VideoCapture(video_path)
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    print(f"Video info: {fps} FPS, {total_frames} frames")

    pose_data = []
    frame_count = 0

    with mp_pose.Pose(
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5,
        model_complexity=1) as pose:

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            # Process every nth frame based on sample_rate
            if frame_count % sample_rate == 0:
                # Convert BGR to RGB
                image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = pose.process(image_rgb)

                if results.pose_landmarks:
                    features = extract_pose_features(results.pose_landmarks)
                    features['frame'] = frame_count
                    features['time'] = frame_count / fps
                    pose_data.append(features)

            frame_count += 1

    cap.release()
    print(f"✓ Processing complete! Extracted {len(pose_data)} poses")

    return pd.DataFrame(pose_data)

def convert_all_joints_to_leading_trailing(cycle_data, strike_foot):
    joints = set()
    for col in cycle_data.columns:
        if col.startswith('left_'):
            joints.add(col.replace('left_', '').rsplit('_', 1)[0])
        elif col.startswith('right_'):
            joints.add(col.replace('right_', '').rsplit('_', 1)[0])

    for joint in joints:
        for axis in ['x', 'y', 'z','angle']:  # เผื่อมี z-axis หรือ angle ด้วย
            left_col = f'left_{joint}_{axis}'
            right_col = f'right_{joint}_{axis}'
            leading_col = f'leading_{joint}_{axis}'
            trailing_col = f'trailing_{joint}_{axis}'
            if left_col in cycle_data.columns and right_col in cycle_data.columns:
                if strike_foot == 'left':
                    cycle_data[leading_col] = cycle_data[left_col]
                    cycle_data[trailing_col] = cycle_data[right_col]
                else:
                    cycle_data[leading_col] = cycle_data[right_col]
                    cycle_data[trailing_col] = cycle_data[left_col]

    return cycle_data

def process_and_label_gait_cycles(pose_data):
    gait_cycles, left_strikes, right_strikes = detect_gait_cycles(pose_data)
    all_cycles = []

    for cycle_info in gait_cycles:
        cycle_data = extract_single_gait_cycle(pose_data, cycle_info)
        cycle_data = convert_all_joints_to_leading_trailing(cycle_data, cycle_info['foot'])
        all_cycles.append(cycle_data)

    labeled_pose_data = pd.concat(all_cycles, ignore_index=True)

    cols_to_drop = [col for col in labeled_pose_data.columns if col.startswith('left_') or col.startswith('right_')]
    labeled_pose_data = labeled_pose_data.drop(columns=cols_to_drop)
    

    return labeled_pose_data, gait_cycles, left_strikes, right_strikes

def feature_measure_gait_phases(cycle_data):
    """Calculate mean of gait features for each gait phase"""

    phases = {
        'Initial Contact': (0, 2),
        'Mid Stance': (20, 40),
        'Toe Off': (60, 70),
        'Swing Phase': (70, 100)
    }

    features = [
        'trunk_lean', 'stride_width', 'center_of_mass_y', 'arm_swing_ratio',
        'leading_elbow_angle', 'trailing_elbow_angle',
        'leading_hip_angle', 'trailing_hip_angle',
        'leading_ankle_x', 'trailing_ankle_x',
        'leading_ankle_y', 'trailing_ankle_y',
        'leading_knee_angle', 'trailing_knee_angle'
    ]

    phase_analysis = {}

    for phase_name, (start, end) in phases.items():
        phase_data = cycle_data[
            (cycle_data['cycle_progress'] >= start) &
            (cycle_data['cycle_progress'] < end)
        ]

        result = {}
        for feat in features:
            if feat in phase_data.columns:
                result[f'mean_{feat}'] = phase_data[feat].mean()
            else:
                result[f'mean_{feat}'] = None  # หรือ np.nan เพื่อแทนค่าที่ไม่มี

        phase_analysis[phase_name] = result

    return phase_analysis

def phase_analysis_to_df(phase_dict):
    """Convert phase analysis dict to DataFrame"""
    return pd.DataFrame.from_dict(phase_dict, orient='index')

def analyze_videos_with_bootstrap(video_paths, n_samples=5000):
    all_cycles_data = []

    for video_path in video_paths:
        print(f"▶ Processing: {video_path}")
        pose_data = process_video(video_path)
        labeled_data, gait_cycles, _, _ = process_and_label_gait_cycles(pose_data)

        for cycle_info in gait_cycles:
            cycle_data = extract_single_gait_cycle(labeled_data, cycle_info)
            normalized_cycle = normalize_gait_cycle(cycle_data)  # Resample ให้ frame count เท่ากัน
            all_cycles_data.append(normalized_cycle)

    if len(all_cycles_data) == 0:
        print("✘ No gait cycles extracted.")
        return {}, None

    # Bootstrap resampling
    bootstrap_results = []
    resampled_cycles = []

    for _ in range(n_samples):
        sampled_cycle = random.choice(all_cycles_data)
        phase_result = feature_measure_gait_phases(sampled_cycle)
        bootstrap_results.append(phase_result)
        resampled_cycles.append(sampled_cycle)

    # รวม mean feature per gait phase
    phases = bootstrap_results[0].keys()
    final_result = {}

    for phase in phases:
        phase_dicts = [sample[phase] for sample in bootstrap_results]
        phase_df = pd.DataFrame(phase_dicts)

        phase_means = {
            col: phase_df[col].mean()
            for col in phase_df.columns
        }

        final_result[phase] = phase_means

    # รวม resampled cycles เป็น mean cycle
    concatenated = pd.concat(resampled_cycles, axis=0)
    mean_cycle_df = concatenated.groupby(concatenated.index).mean()

    return final_result, mean_cycle_df

#####################################################################
# Comparison Functions
#####################################################################

def reshape_to_feature_table(df, selected_features):
    reshaped = pd.melt(
        df,
        id_vars=['cycle_progress'],
        value_vars=selected_features,
        var_name='feature',
        value_name='value'
    )

    phases = {
        'Initial Contact': (0, 2),
        'Mid Stance': (20, 40),
        'Toe Off': (60, 70),
        'Swing Phase': (70, 100)
    }

    def get_phase(progress):
        for phase, (start, end) in phases.items():
            if start <= progress <= end:
                return phase

    reshaped['phase'] = reshaped['cycle_progress'].apply(get_phase)
    return reshaped

def flatten_cycle(cycle_data, selected_features):
    flatten = []
    for feature in selected_features:
        flatten.extend(cycle_data[feature].to_numpy())
    return flatten

# def compare_cosine_similarity_all_phases(user_dict, elite_dict):
#     similarity_dict = {}

#     for phase in elite_dict.keys():
#         if phase not in user_dict:
#             print(f"⚠️ Phase '{phase}' not found in user data. Skipping...")
#             continue

#         elite_features = elite_dict[phase]
#         user_features = user_dict[phase]

#         # Get only common features
#         common_features = sorted(set(user_features.keys()).intersection(elite_features.keys()))

#         if not common_features:
#             print(f"⚠️ No common features found in phase '{phase}'. Skipping...")
#             continue

#         user_vector = np.array([user_features[f] for f in common_features])
#         elite_vector = np.array([elite_features[f] for f in common_features])

#         # Normalize vectors
#         user_norm = user_vector / (np.linalg.norm(user_vector) + 1e-8)
#         elite_norm = elite_vector / (np.linalg.norm(elite_vector) + 1e-8)

#         similarity = 1 - cosine(user_norm, elite_norm)

#         similarity_dict[phase] = similarity

#     return similarity_dict


def interpolate_vector(vector, target_length):
    original_length = len(vector)
    if original_length == target_length:
        return vector

    # Create original and target indices
    original_indices = np.linspace(0, 1, original_length)
    target_indices = np.linspace(0, 1, target_length)

    # Interpolate
    interpolator = interp1d(original_indices, vector, kind='linear')
    return interpolator(target_indices)

def calculate_consine_similarity(user_vector, elite_vector):
    # Interpolate both to the same (max) length
    max_len = max(len(user_vector), len(elite_vector))
    user_interp = interpolate_vector(user_vector, max_len)
    elite_interp = interpolate_vector(elite_vector, max_len)

    # Normalize
    user_norm = user_interp / (np.linalg.norm(user_interp) + 1e-8)
    elite_norm = elite_interp / (np.linalg.norm(elite_interp) + 1e-8)

    # Compute cosine similarity
    similarity = 1 - cosine(user_norm, elite_norm)
    return similarity

def get_similarity_results(user_reshaped, elite_reshaped):
    phases = ['Initial Contact', 'Mid Stance', 'Toe Off', 'Swing Phase']

    # --- Overall similarity (include all data, including phase=None) ---
    overall_similarity = calculate_consine_similarity(
        user_reshaped['value'].to_numpy(),
        elite_reshaped['value'].to_numpy()
    )

    # --- Per-phase similarity (exclude phase=None, skip if no data) ---
    phases_similarity_dict = {}
    for phase in phases:
        user_phase_data = user_reshaped[user_reshaped['phase'] == phase]['value']
        elite_phase_data = elite_reshaped[elite_reshaped['phase'] == phase]['value']

        if user_phase_data.empty or elite_phase_data.empty:
            continue  # Skip if either side is missing

        min_len = min(len(user_phase_data), len(elite_phase_data))
        similarity = calculate_consine_similarity(
            user_phase_data.to_numpy()[:min_len],
            elite_phase_data.to_numpy()[:min_len]
        )

        phases_similarity_dict[phase] = similarity

    return overall_similarity, phases_similarity_dict

# def calculate_statistical_deviation(user_data_by_phase, elite_benchmarks):
#     """Calculate percentage deviation of user features from elite benchmarks (mean only)"""

#     deviations = {}

#     for phase_name, user_metrics in user_data_by_phase.items():
#         if phase_name not in elite_benchmarks:
#             continue
        
#         phase_devs = {}
#         for feature, user_value in user_metrics.items():
#             if feature in elite_benchmarks[phase_name]:
#                 elite_mean = elite_benchmarks[phase_name][feature]
#                 if elite_mean == 0:
#                     deviation_percent = None  # หรือกำหนดเป็น 0 หรือค่าอื่นตามเหมาะสม
#                 else:
#                     deviation_percent = abs(user_value - elite_mean) / abs(elite_mean) * 100
                
#                 phase_devs[feature] = {
#                     'user_value': user_value,
#                     'elite_mean': elite_mean,
#                     'deviation_percent': deviation_percent
#                 }
#         deviations[phase_name] = phase_devs

#     return deviations

def calculate_statistical_deviation_from_df(user_reshaped, elite_reshaped):
    deviations = {}

    # Exclude None phase
    user_reshaped = user_reshaped[user_reshaped['phase'].notna()]
    elite_reshaped = elite_reshaped[elite_reshaped['phase'].notna()]

    phases = user_reshaped['phase'].unique()
    features = user_reshaped['feature'].unique()

    for phase in phases:
        phase_devs = {}

        for feature in features:
            user_vals = user_reshaped[
                (user_reshaped['phase'] == phase) & (user_reshaped['feature'] == feature)
            ]['value']

            elite_vals = elite_reshaped[
                (elite_reshaped['phase'] == phase) & (elite_reshaped['feature'] == feature)
            ]['value']

            if user_vals.empty or elite_vals.empty:
                continue

            user_mean = user_vals.mean()
            elite_mean = elite_vals.mean()

            if elite_mean == 0:
                deviation_percent = None
            else:
                deviation_percent = abs(user_mean - elite_mean) / abs(elite_mean) * 100

            phase_devs[feature] = deviation_percent

        deviations[phase] = phase_devs

    return deviations

def dtw_distance(series1, series2):
    """Simple DTW implementation for time series comparison"""
    n, m = len(series1), len(series2)
    dtw_matrix = np.full((n+1, m+1), np.inf)
    dtw_matrix[0, 0] = 0

    for i in range(1, n+1):
        for j in range(1, m+1):
            cost = abs(series1[i-1] - series2[j-1])
            dtw_matrix[i, j] = cost + min(dtw_matrix[i-1, j],    # insertion
                                          dtw_matrix[i, j-1],    # deletion
                                          dtw_matrix[i-1, j-1])  # match

    return dtw_matrix[n, m]

def dtw_compare_gait_phases(user_cycle_data, elite_cycle_data):
    phases = {
        'Initial Contact': (0, 2),
        'Mid Stance': (20, 40),
        'Toe Off': (60, 70),
        'Swing Phase': (70, 100)
    }

    features = [
        'trunk_lean', 'stride_width', 'center_of_mass_y', 'arm_swing_ratio',
        'leading_elbow_angle', 'trailing_elbow_angle',
        'leading_hip_angle', 'trailing_hip_angle',
        'leading_ankle_x', 'trailing_ankle_x',
        'leading_ankle_y', 'trailing_ankle_y',
        'leading_knee_angle', 'trailing_knee_angle'
    ]
    
    results = {}

    for phase_name, (start, end) in phases.items():
        # filter data by phase progress
        user_phase = user_cycle_data[(user_cycle_data['cycle_progress'] >= start) & (user_cycle_data['cycle_progress'] < end)]
        elite_phase = elite_cycle_data[(elite_cycle_data['cycle_progress'] >= start) & (elite_cycle_data['cycle_progress'] < end)]

        phase_result = {}

        for feat in features:
            if feat in user_phase.columns and feat in elite_phase.columns:
                user_series = user_phase[feat].values
                elite_series = elite_phase[feat].values

                # Avoid empty series
                if len(user_series) > 0 and len(elite_series) > 0:
                    dist = dtw_distance(user_series, elite_series)
                    phase_result[feat] = dist
                else:
                    phase_result[feat] = None
            else:
                phase_result[feat] = None

        results[phase_name] = phase_result

    return results

def create_model(input_size, encoder_type, decoder_type, hidden_size=64, bottleneck_size=32):
    class RNNModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.encoder_rnn = getattr(nn, encoder_type)(input_size, hidden_size, batch_first=True)
            self.bottleneck = nn.Linear(hidden_size, bottleneck_size)
            self.decoder_rnn = getattr(nn, decoder_type)(bottleneck_size, hidden_size, batch_first=True)
            self.output_layer = nn.Linear(hidden_size, input_size)

        def forward(self, x):
            if encoder_type == 'LSTM':
                _, (h_n, _) = self.encoder_rnn(x)
            else:
                _, h_n = self.encoder_rnn(x)
            latent = self.bottleneck(h_n[-1])
            z = latent.unsqueeze(1).repeat(1, x.size(1), 1)
            decoded, _ = self.decoder_rnn(z)
            return self.output_layer(decoded)

    return RNNModel()

def load_model(model_path, input_size, encoder_type, decoder_type):
    model = create_model(input_size, encoder_type=encoder_type, decoder_type=decoder_type)
    model.load_state_dict(torch.load(model_path, map_location='cpu'))
    model.eval()
    return model

def evaluate_gait_anomaly(model, pose_data, selected_features, num_points=100):
    model.eval()
    device = next(model.parameters()).device
    cycles, _, _ = detect_gait_cycles(pose_data)

    if not cycles:
        return None, "No gait cycles found"

    labeled_pose_data, gait_cycles, left_strikes, right_strikes = process_and_label_gait_cycles(pose_data)
    # cycle = extract_single_gait_cycle(labeled_pose_data, cycles[0])
    # norm_cycle = normalize_gait_cycle(cycle, num_points)
    norm_cycle = aggregate_normalized_cycles(labeled_pose_data, gait_cycles)


    if not all(f in norm_cycle.columns for f in selected_features):
        return None, "Missing features in pose data"

    x = torch.tensor(norm_cycle[selected_features].values, dtype=torch.float32).to(device)
    # x_flat = x.view(-1, x.shape[-1])
    x_flat = x.unsqueeze(0)  # add batch dimension: [1, T, F]
    recon = model(x_flat)

    with torch.no_grad():
        recon = model(x_flat)
        mse = torch.mean((x_flat - recon) ** 2, dim=1)
        mape = torch.mean(torch.abs((x_flat - recon) / (x_flat + 1e-8)), dim=1) * 100
        avg_error = mse.mean().item()
        avg_mape = mape.mean().item()

    return avg_error, mse.cpu().numpy(), avg_mape, mape.cpu().numpy(), recon, x_flat

def plot_reconstruction_boxplot(x_flat, recon, feature_name, save_path=None):
    # ✅ Convert to NumPy
    if torch.is_tensor(x_flat):
        x_flat = x_flat.detach().cpu().numpy()
    if torch.is_tensor(recon):
        recon = recon.detach().cpu().numpy()

    # ✅ Reshape: (batch_size, sequence_len, 1) → (sequence_len,)
    x_flat = x_flat.reshape(-1)  # หรือ x_flat[0, :, 0]
    recon = recon.reshape(-1)

    # ✅ Compute MAPE per timestep
    mape_per_timestep = np.abs((x_flat - recon) / (x_flat + 1e-8)) * 100

    # ✅ Plot
    plt.figure(figsize=(5, 4))
    plt.boxplot(mape_per_timestep)
    plt.ylabel("Reconstruction MAPE (%)")
    plt.title(f"Boxplot of Reconstruction Error – {feature_name}")

    if save_path:
        plt.savefig(save_path, bbox_inches="tight")
        print(f"📦 Saved boxplot to {save_path}")
    else:
        plt.show()

def evaluate_models_and_collect_mape(pose_df, model_dir='.'):
    labeled_pose_data, gait_cycles, left_strikes, right_strikes = process_and_label_gait_cycles(pose_df)

    feature_mape_dict = {}

    model_files = glob.glob(os.path.join(model_dir, "best_*_lr*_bs*_pt*_*.pt"))
    print(f"🧠 Found {len(model_files)} model files")

    for model_path in model_files:
        model_filename = os.path.basename(model_path)
        parts = model_filename.split("_")

        if len(parts) < 7:
            print(f"⚠️ Skipping malformed filename: {model_filename}")
            continue

        encoder_type = parts[1]
        decoder_type = parts[2]
        feature = "_".join(parts[6:]).replace(".pt", "")

        print(f"\n📦 Loading model: {model_filename}")
        print(f"🔍 Feature: {feature} | Encoder: {encoder_type} | Decoder: {decoder_type}")

        model = load_model(model_path, input_size=1, encoder_type=encoder_type, decoder_type=decoder_type)

        if feature not in labeled_pose_data.columns:
            print(f"❌ Feature '{feature}' not found in pose_df")
            continue

        # single_feature_df = pose_df[[feature]].copy()
        result = evaluate_gait_anomaly(model, pose_df, [feature])

        if isinstance(result, tuple):
            _, _, mape_avg, _, recon, x_flat = result
            print(f"✅ {feature}: Avg MAPE = {mape_avg:.2f}%")
            feature_mape_dict[feature] = mape_avg

            #plot_reconstruction_boxplot(
                #x_flat, recon,
                #feature_name=feature
            #)

        else:
            print(f"⚠️ Error evaluating {feature}: {result}")

    return feature_mape_dict

#####################################################################
# Generative AI
#####################################################################

def generate_ai_feedback(overall_similarity, similarities, deviations, dtw_distances, autoencoder_mape_result=None, language='English',user_age="20", user_height="180", user_weight="70", user_gender="male", user_question=None):
    # === Prepare summaries ===

    similarity_summary = "\n".join([
        f"- {phase.replace('_', ' ').title()}: similarity score = {score:.2f}"
        for phase, score in similarities.items()
    ])

    dtw_deviation_summary = []
    for phase, metrics in deviations.items():
        dtw_deviation_summary.append(f"**{phase} phase**")
        for metric, deviation_percent in metrics.items():
            dtw_deviation_summary.append(
                f"- {metric.replace('_', ' ').title()}: deviation = {deviation_percent:.1f}%"
            )
        dtw_deviation_summary.append("")  # เว้นบรรทัดระหว่าง phase
    dtw_summary_text = "\n".join(dtw_deviation_summary)

    ae_summary_text = ""
    if autoencoder_mape_result:
        ae_summary_text = "\n".join([
            f"- {feat.replace('_', ' ')}: MAPE = {mape:.1f}%"
            for feat, mape in autoencoder_mape_result.items()
        ])

    # === DTW Distances summary ===
    if dtw_distances:
        flat_dtw_list = []
        for phase, metrics in dtw_distances.items():
            flat_dtw_list.append(f"**{phase} phase**")
            for metric, value in metrics.items():
                flat_dtw_list.append(f"- {metric.replace('_', ' ').title()}: {value:.2f}")
            flat_dtw_list.append("")  # เพิ่มบรรทัดว่างระหว่าง phases
        dtw_distance_summary = "\n".join(flat_dtw_list)
    else:
        dtw_distance_summary = "No DTW distance data available."

    # === Prompt to GPT ===
    if user_question is None:
        # Initial analysis feedback
        full_prompt = f"""
You are an expert running coach and movement analyst. A user has uploaded their running video, and it has been analyzed and compared against elite runner standards.

Below is the analysis data:

**1. Overall Similarity Scores (compared to elite runners):**
{overall_similarity}

**2. Phase Similarity Scores (compared to elite runners):**
{similarity_summary}

**3. Dynamic Time Warping (DTW) Distances:**
{dtw_distance_summary}

**4. Gait Deviations Detected (DTW-based deviation percentages):**
{dtw_summary_text}

**5. Feature Reconstruction Errors (Autoencoder MAPE):**
{ae_summary_text if ae_summary_text else 'All features were well reconstructed.'}

**6. Other personal information:
User's Age: {user_age},
User's Height: {user_height},
User's Weight: {user_weight},
User's Gender: {user_gender},
---

Based on this information, please write a clear and friendly feedback report for the user that includes:
- An overall summary of their running form compared to elite runners.
- Observations about any significant movement deviations or inefficiencies.
- Suggested exercises or drills to help improve.
- A brief note on any potential injury risks based on these deviations.

Avoid technical jargon. Write it in the style of a knowledgeable but friendly human coach speaking to an amateur runner who wants to improve and avoid injury.

PLEASE! Answer in {language} language
"""
    else:
        # Follow-up question
        full_prompt = f"""
You are an expert running coach continuing a conversation about a user's gait analysis results.

Below is the complete analysis data:

**1. Overall Similarity Scores (compared to elite runners):**
{overall_similarity}

**2. Phase Similarity Scores (compared to elite runners):**
{similarity_summary}

**3. Dynamic Time Warping (DTW) Distances:**
{dtw_distance_summary}

**4. Gait Deviations Detected (DTW-based deviation percentages):**
{dtw_summary_text}

**5. Feature Reconstruction Errors (Autoencoder MAPE):**
{ae_summary_text if ae_summary_text else 'All features were well reconstructed.'}

**6. User's personal information:**
User's Age: {user_age}
User's Height: {user_height}
User's Weight: {user_weight}
User's Gender: {user_gender}

**USER'S FOLLOW-UP QUESTION:** {user_question}

Please provide a helpful, specific answer based on the analysis results. If the question is about:
- Specific exercises: Provide detailed instructions with sets/reps
- Injury prevention: Give specific advice based on their biomechanics
- Technical terms: Explain in simple language
- Improvements: Suggest concrete steps with timeline
- Form corrections: Reference specific phases and metrics from the analysis

Keep your response conversational and supportive, like a knowledgeable coach speaking to their athlete.

PLEASE answer in {language} language.
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a friendly and expert running coach specializing in biomechanics and injury prevention."},
                {"role": "user", "content": full_prompt}
            ],
            max_tokens=10000,
            temperature=0.7
        )
        feedback = response.choices[0].message.content.strip()
    except Exception as e:
        feedback = f"⚠️ Error generating feedback: {e}"

    return feedback

#####################################################################
# Visualization
#####################################################################

def plot_overall_and_phase_similarity(phase_means, overall_similarity):
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns
    import streamlit as st

    # กำหนดลำดับ phases ที่ต้องการให้แสดงจากบนลงล่าง
    phases_order = ['Initial Contact', 'Mid Stance', 'Toe Off', 'Swing Phase']
    phases = [p for p in phases_order if p in phase_means]  # กรองแค่ phase ที่มีในข้อมูล

    values = np.array([phase_means[p] for p in phases])
    
    # ใช้ค่าที่รับเข้ามา แทนที่จะคำนวณค่าเฉลี่ย
    overall_mean = overall_similarity * 100  # ให้เป็นเปอร์เซ็นต์

    fig, axs = plt.subplots(2, 1, figsize=(8, 7),
                            gridspec_kw={'height_ratios': [2, 1], 'hspace': 0.1})

    # Donut chart
    sizes = [overall_mean, 100 - overall_mean]
    colors = ['#3B5998', '#D3D3D3']

    wedges, texts = axs[0].pie(
        sizes,
        labels=['', ''],
        startangle=90,
        colors=colors,
        wedgeprops={'width': 0.4},
        counterclock=False
    )
    axs[0].text(0, 0, f"{overall_mean:.1f}%", ha='center', va='center',
                fontsize=18, fontweight='bold', color='#3B5998')

    axs[0].set_aspect('equal')
    axs[0].axis('off')
    axs[0].set_title('Overall Similarity', fontsize=13, weight='bold')

    # Bar gauge horizontal
    remaining_values = 100 - (values * 100)
    axs[1].barh(phases, values * 100, color='#5A7FCF')
    axs[1].barh(phases, remaining_values, left=values * 100, color='#D3D3D3')

    axs[1].set_xlim(0, 100)
    axs[1].set_xlabel('Similarity (%)', fontsize=11)
    axs[1].set_title('Phase Similarity', fontsize=13, weight='bold')
    axs[1].invert_yaxis()  # ไล่จากบนลงล่างตามลำดับ phases_order

    for i, v in enumerate(values * 100):
        axs[1].text(v / 2, i, f"{v:.1f}%", va='center', ha='center', fontsize=10, weight='bold', color='white')

    st.pyplot(fig)

def plot_relative_feature_diff_bar(user_cycle, elite_cycle, feature,
                                   threshold_yellow=20, threshold_orange=25, threshold_red=30):
    if feature not in user_cycle.columns or feature not in elite_cycle.columns:
        raise ValueError(f"Feature '{feature}' not found in both dataframes.")
    if len(user_cycle) != len(elite_cycle):
        raise ValueError("User and elite dataframes must have the same length.")

    user_sorted = user_cycle.sort_values(by="cycle_progress").reset_index(drop=True)
    elite_sorted = elite_cycle.sort_values(by="cycle_progress").reset_index(drop=True)

    elite_values = elite_sorted[feature].replace(0, np.nan)  # avoid div0
    relative_diff = (user_sorted[feature] - elite_values) / elite_values * 100
    cycle_progress = user_sorted["cycle_progress"]

    bar_colors = []
    for val in relative_diff:
        abs_val = abs(val)
        if abs_val > threshold_red:
            bar_colors.append('red')
        elif abs_val > threshold_orange:
            bar_colors.append('orange')
        elif abs_val > threshold_yellow:
            bar_colors.append('#FFEB3B')  # pastel yellow
        else:
            bar_colors.append('lightgray')

    fig, ax = plt.subplots(figsize=(12, 5))
    ax.bar(cycle_progress, relative_diff, width=1.0, color=bar_colors, alpha=0.8, edgecolor='black')

    ax.axhline(0, color='black', linewidth=1)
    ax.axhline(threshold_yellow, color='#FFEB3B', linestyle='--', linewidth=1, label=f'±{threshold_yellow}% Threshold')
    ax.axhline(-threshold_yellow, color='#FFEB3B', linestyle='--', linewidth=1)
    ax.axhline(threshold_orange, color='orange', linestyle='--', linewidth=1, label=f'±{threshold_orange}% Threshold')
    ax.axhline(-threshold_orange, color='orange', linestyle='--', linewidth=1)
    ax.axhline(threshold_red, color='red', linestyle='--', linewidth=1, label=f'±{threshold_red}% Threshold')
    ax.axhline(-threshold_red, color='red', linestyle='--', linewidth=1)

    ax.set_title(f"Relative Difference in {feature.replace('_', ' ').title()} (% vs Elite)", fontsize=14)
    ax.set_xlabel("Gait Cycle Progress (%)", fontsize=12)
    ax.set_ylabel("Relative Difference (%)", fontsize=12)
    ax.legend()
    ax.grid(True, linestyle='--', alpha=0.5)

    plt.tight_layout()
    st.pyplot(fig)
    
    return fig, ax

KEY_RUNNING_JOINTS = {
                    'left_ankle': {'landmark': 27, 'color': (255, 0, 0), 'size': 8},
                    'right_ankle': {'landmark': 28, 'color': (255, 0, 0), 'size': 8},
                    'left_knee': {'landmark': 25, 'color': (0, 255, 0), 'size': 8},
                    'right_knee': {'landmark': 26, 'color': (0, 255, 0), 'size': 8},
                    'left_hip': {'landmark': 23, 'color': (0, 0, 255), 'size': 8},
                    'right_hip': {'landmark': 24, 'color': (0, 0, 255), 'size': 8},
                    'left_shoulder': {'landmark': 11, 'color': (255, 255, 0), 'size': 6},
                    'right_shoulder': {'landmark': 12, 'color': (255, 255, 0), 'size': 6}
}
KEY_CONNECTIONS = [
                    ('left_ankle', 'left_knee'),
                    ('left_knee', 'left_hip'),
                    ('right_ankle', 'right_knee'),
                    ('right_knee', 'right_hip'),
                    ('left_hip', 'right_hip'),
                    ('left_shoulder', 'right_shoulder')
]

def process_full_video_with_joints(video_path, sample_rate=1, show_all_joints=False):
    """
    ประมวลผลวิดีโอพร้อมการแสดงข้อต่อและตรวจจับรอบการเดิน 
    โดยส่งคืน path ของไฟล์ที่ประมวลผลแล้วและจำนวนรอบ
    """
    from datetime import datetime
    
    # ตรวจสอบว่าไฟล์วิดีโอมีอยู่
    if not os.path.exists(video_path):
        raise FileNotFoundError(f"ไม่พบไฟล์วิดีโอ: {video_path}")

    # เริ่มต้น Streamlit progress bar
    progress_bar = st.progress(0)
    status_text = st.empty()
    status_text.text("กำลังเริ่มประมวลผลวิดีโอ...")

    try:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError("ไม่สามารถเปิดวิดีโอได้")

        # ได้ค่าพารามิเตอร์วิดีโอ
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        print(f"Video info: {width}x{height}, {fps} FPS, {total_frames} frames")

        # สร้างไฟล์ชั่วคราวสำหรับวิดีโอ output
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
            output_path = tmp_file.name

        # ลอง codec หลายแบบ
        codecs_to_try = [
            cv2.VideoWriter_fourcc(*'mp4v'),
            cv2.VideoWriter_fourcc(*'XVID'),
            cv2.VideoWriter_fourcc(*'H264'),
            cv2.VideoWriter_fourcc(*'X264')
        ]
        
        out = None
        for codec in codecs_to_try:
            out = cv2.VideoWriter(output_path, codec, fps, (width, height))
            if out.isOpened():
                print(f"Using codec: {codec}")
                break
        
        if out is None or not out.isOpened():
            raise ValueError("ไม่สามารถสร้าง VideoWriter ด้วย codec ใดๆ ได้")

        # สำหรับการตรวจจับรอบการเดิน
        ankle_positions = []
        frame_count = 0
        current_gait_cycle = 1
        last_strike_frame = 0
        processed_frames = 0

        with mp_pose.Pose(
            min_detection_confidence=0.3,  # ลดค่าให้ตรวจจับง่ายขึ้น
            min_tracking_confidence=0.3,   # ลดค่าให้ตรวจจับง่ายขึ้น
            model_complexity=1
        ) as pose:
            
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break

                # สร้างสำเนาของเฟรมต้นฉบับ
                output_frame = frame.copy()

                # อัปเดตความคืบหน้า
                if total_frames > 0:
                    progress = min(0.95, frame_count / total_frames)
                    progress_bar.progress(progress)
                    
                    if frame_count % max(1, total_frames // 20) == 0:
                        status_text.text(f"ประมวลผล: {int(progress * 100)}% ({frame_count}/{total_frames} เฟรม)")

                # ประมวลผลเฉพาะเฟรมที่เลือกตาม sample_rate
                if frame_count % sample_rate == 0:
                    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    results = pose.process(image_rgb)

                    if results.pose_landmarks:
                        # เก็บตำแหน่งข้อเท้าสำหรับตรวจจับรอบ
                        left_ankle = results.pose_landmarks.landmark[27]  # left ankle
                        right_ankle = results.pose_landmarks.landmark[28]  # right ankle
                        ankle_positions.append({
                            'frame': frame_count,
                            'left_y': left_ankle.y,
                            'right_y': right_ankle.y
                        })

                        # ตรวจจับ foot strike
                        if len(ankle_positions) > 15:
                            recent_left_y = [pos['left_y'] for pos in ankle_positions[-15:]]
                            if (len(recent_left_y) >= 3 and 
                                recent_left_y[-1] > recent_left_y[-2] and 
                                recent_left_y[-2] < recent_left_y[-3]):
                                if frame_count - last_strike_frame > fps // 3:
                                    current_gait_cycle += 1
                                    last_strike_frame = frame_count

                        # วาดข้อต่อบนเฟรม output
                        if show_all_joints:
                            # แสดงข้อต่อทั้งหมด
                            mp_drawing.draw_landmarks(
                                output_frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,
                                mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2, circle_radius=2),
                                mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2, circle_radius=2)
                            )
                        else:
                            # แสดงเฉพาะข้อต่อสำคัญ (ครบตามรูป)
                            key_landmarks = {
                                'left_ankle': 27, 'right_ankle': 28,
                                'left_knee': 25, 'right_knee': 26,
                                'left_hip': 23, 'right_hip': 24,
                                'left_shoulder': 11, 'right_shoulder': 12,
                                'left_elbow': 13, 'right_elbow': 14,
                                'left_wrist': 15, 'right_wrist': 16,
                                'left_heel': 29, 'right_heel': 30,      # เพิ่ם heel
                                'left_foot': 31, 'right_foot': 32       # เพิ่ม foot (foot index)
                            }
                            
                            colors = {
                                'ankle': (0, 0, 255),    # แดง
                                'knee': (0, 255, 0),     # เขียว
                                'hip': (255, 0, 0),      # น้ำเงิน
                                'shoulder': (0, 255, 255), # เหลือง
                                'elbow': (255, 0, 255),  # ม่วง
                                'wrist': (255, 165, 0),  # ส้ม
                                'heel': (128, 0, 128),   # ม่วงเข้ม
                                'foot': (0, 128, 255)    # ฟ้า
                            }
                            
                            for joint_name, landmark_idx in key_landmarks.items():
                                landmark = results.pose_landmarks.landmark[landmark_idx]
                                if landmark.visibility > 0.3:  # เฉพาะข้อต่อที่มองเห็นได้ชัด
                                    x = int(landmark.x * width)
                                    y = int(landmark.y * height)
                                    
                                    # กำหนดสี
                                    if 'ankle' in joint_name:
                                        color = colors['ankle']
                                    elif 'knee' in joint_name:
                                        color = colors['knee']
                                    elif 'hip' in joint_name:
                                        color = colors['hip']
                                    elif 'shoulder' in joint_name:
                                        color = colors['shoulder']
                                    elif 'elbow' in joint_name:
                                        color = colors['elbow']
                                    elif 'wrist' in joint_name:
                                        color = colors['wrist']
                                    elif 'heel' in joint_name:
                                        color = colors['heel']
                                    elif 'foot' in joint_name:
                                        color = colors['foot']
                                    
                                    cv2.circle(output_frame, (x, y), 6, color, -1)
                                    cv2.circle(output_frame, (x, y), 8, (255, 255, 255), 2)

                            # วาดเส้นเชื่อมข้อต่อ (ครบตามโครงสร้างร่างกาย)
                            connections = [
                                # ขาซ้าย: heel -> ankle -> knee -> hip
                                (29, 27), (27, 25), (25, 23),  
                                # ขาขวา: heel -> ankle -> knee -> hip  
                                (30, 28), (28, 26), (26, 24),
                                # เท้า: ankle -> foot
                                (27, 31), (28, 32),
                                # ลำตัว: สะโพกเชื่อมกัน
                                (23, 24),
                                # ไหล่เชื่อมกัน
                                (11, 12),
                                # แขนซ้าย: shoulder -> elbow -> wrist
                                (11, 13), (13, 15),
                                # แขนขวา: shoulder -> elbow -> wrist
                                (12, 14), (14, 16)
                            ]
                            
                            for start_idx, end_idx in connections:
                                start_landmark = results.pose_landmarks.landmark[start_idx]
                                end_landmark = results.pose_landmarks.landmark[end_idx]
                                
                                if start_landmark.visibility > 0.3 and end_landmark.visibility > 0.3:
                                    x1 = int(start_landmark.x * width)
                                    y1 = int(start_landmark.y * height)
                                    x2 = int(end_landmark.x * width)
                                    y2 = int(end_landmark.y * height)
                                    cv2.line(output_frame, (x1, y1), (x2, y2), (255, 255, 255), 3)

                        # เพิ่มข้อมูลการวิเคราะห์
                        try:
                            features = extract_pose_features(results.pose_landmarks)
                            
                            # สร้างแผงข้อมูล
                            overlay = output_frame.copy()
                            panel_height = 200  # ลดความสูงลง
                            panel_width = 450   
                            cv2.rectangle(overlay, (10, 10), (panel_width, panel_height), (0, 0, 0), -1)
                            cv2.addWeighted(overlay, 0.8, output_frame, 0.2, 0, output_frame)

                            font = cv2.FONT_HERSHEY_SIMPLEX
                            cv2.putText(output_frame, "Gait Analysis", (20, 35), font, 0.7, (255, 255, 255), 2)
                            cv2.line(output_frame, (20, 45), (panel_width-20, 45), (255, 255, 255), 1)
                            
                            y_offset = 65
                            cv2.putText(output_frame, f"Frame: {frame_count}/{total_frames}", (20, y_offset), font, 0.5, (200, 200, 200), 1)
                            cv2.putText(output_frame, f"Cycle: #{current_gait_cycle}", (250, y_offset), font, 0.5, (200, 200, 200), 1)
                            
                            # มุมข้อต่อทั้งหมด
                            y_offset += 30
                            cv2.putText(output_frame, "Joint Angles:", (20, y_offset), font, 0.5, (255, 255, 255), 1)
                            
                            # แถว 1: เข่า
                            y_offset += 20
                            cv2.putText(output_frame, f"L.Knee: {features['left_knee_angle']:.1f}°", (20, y_offset), font, 0.4, (0, 255, 0), 1)
                            cv2.putText(output_frame, f"R.Knee: {features['right_knee_angle']:.1f}°", (150, y_offset), font, 0.4, (0, 255, 0), 1)
                            cv2.putText(output_frame, f"L.Hip: {features['left_hip_angle']:.1f}°", (280, y_offset), font, 0.4, (255, 0, 0), 1)
                            
                            # แถว 2: สะโพก และ ข้อศอก
                            y_offset += 18
                            cv2.putText(output_frame, f"R.Hip: {features['right_hip_angle']:.1f}°", (20, y_offset), font, 0.4, (255, 0, 0), 1)
                            cv2.putText(output_frame, f"L.Elbow: {features['left_elbow_angle']:.1f}°", (150, y_offset), font, 0.4, (255, 0, 255), 1)
                            cv2.putText(output_frame, f"R.Elbow: {features['right_elbow_angle']:.1f}°", (280, y_offset), font, 0.4, (255, 0, 255), 1)
                            
                            # แถว 3: การวิเคราะห์ท่าทาง
                            y_offset += 18
                            cv2.putText(output_frame, f"Trunk Lean: {features['trunk_lean']:.1f}°", (20, y_offset), font, 0.4, (0, 0, 255), 1)
                            cv2.putText(output_frame, f"Stride Width: {features['stride_width']:.3f}", (200, y_offset), font, 0.4, (0, 0, 255), 1)
                            
                            # แถว 4: อัตราส่วน
                            y_offset += 18
                            cv2.putText(output_frame, f"Arm Swing Ratio: {features['arm_swing_ratio']:.3f}", (20, y_offset), font, 0.4, (255, 165, 0), 1)
                            cv2.putText(output_frame, f"CoM Y: {features['center_of_mass_y']:.3f}", (250, y_offset), font, 0.4, (0, 255, 255), 1)
                            
                            # เวลา
                            time_sec = frame_count / fps
                            cv2.putText(output_frame, f"Time: {time_sec:.1f}s", (width - 120, height - 20), font, 0.6, (255, 255, 255), 2)
                            
                        except Exception:
                            # หากไม่สามารถดึงฟีเจอร์ได้
                            cv2.putText(output_frame, f"Frame: {frame_count}", (20, 50), font, 0.7, (255, 255, 255), 2)
                    
                    processed_frames += 1
                else:
                    # ถ้าไม่ใช่เฟรมที่ต้องประมวลผล ให้ใช้เฟรมต้นฉบับ
                    output_frame = frame

                # เขียนเฟรมลงไฟล์ output (ทุกเฟรม)
                success = out.write(output_frame)
                if not success:
                    print(f"Warning: Failed to write frame {frame_count}")
                
                frame_count += 1

        # ปิดทรัพยากร
        cap.release()
        out.release()

        # ตรวจสอบว่าไฟล์ถูกสร้างสำเร็จ
        if not os.path.exists(output_path):
            raise ValueError("ไม่สามารถสร้างไฟล์วิดีโอได้")
            
        file_size = os.path.getsize(output_path)
        if file_size == 0:
            raise ValueError("ไฟล์วิดีโอที่สร้างมีขนาด 0 bytes")

        print(f"Output video created: {file_size} bytes")

        # อัปเดตความคืบหน้าให้เสร็จสิ้น
        progress_bar.progress(1.0)
        status_text.success(f"✅ ประมวลผลเสร็จสิ้น! (ประมวลผล {processed_frames} เฟรม)")
        
        return output_path, current_gait_cycle

    except Exception as e:
        # ปิดทรัพยากรในกรณีเกิดข้อผิดพลาด
        if 'cap' in locals():
            cap.release()
        if 'out' in locals():
            out.release()
        
        status_text.error(f"❌ เกิดข้อผิดพลาด: {str(e)}")
        raise
    finally:
        # ล้าง progress bar
        progress_bar.empty()
        
#####################################################################
# Main
#####################################################################
import streamlit as st
import os
import tempfile
import pandas as pd
import shutil
from datetime import datetime
mp_drawing = mp.solutions.drawing_utils


def main_processing(video_path, language, user_age, user_height, user_weight, user_gender):
    """
    Main processing pipeline for gait analysis
    
    Args:
        video_path (str): Path to the uploaded video file
        language (str): Selected language ("ENG" or "TH")
        user_age (int): User's age
        user_height (int): User's height in cm
        user_weight (int): User's weight in kg
        user_gender (str): User's gender ("male" or "female")
    
    Returns:
        feedback (str): AI generated feedback
        similarities: Similarity analysis results
        normalized_cycle: Normalized gait cycle data
        elite_cycles: Elite benchmark data
    """
    try:
        # Process video to extract pose data
        pose_data = process_video(video_path)
        
        # Process and label gait cycles
        labeled_pose_data, gait_cycles, left_strikes, right_strikes = process_and_label_gait_cycles(pose_data)
        
        # Select middle cycle for analysis
        # mid_cycle_idx = len(gait_cycles) // 2
        # selected_cycle = gait_cycles[mid_cycle_idx]
        # print(f'selected_cycle:{selected_cycle}')

        # Extract and normalize single gait cycle
        # cycle_data = extract_single_gait_cycle(labeled_pose_data, selected_cycle)
        # normalized_cycle = normalize_gait_cycle(cycle_data)
        normalized_cycle = aggregate_normalized_cycles(labeled_pose_data, gait_cycles)

        # Analyze gait phases
        phase_analysis = feature_measure_gait_phases(normalized_cycle)
        
        # Load elite benchmark data
        elite_cycles = pd.DataFrame(dict_elite_cyle)
        
        # Perform comparisons
        selected_features = [
            'trunk_lean','stride_width', 'center_of_mass_y', 'arm_swing_ratio',
            'leading_elbow_angle', 'trailing_elbow_angle',
            'leading_hip_angle', 'trailing_hip_angle',
            'leading_ankle_x', 'trailing_ankle_x',
            'leading_ankle_y', 'trailing_ankle_y',
            'leading_knee_angle', 'trailing_knee_angle',"trunk_lean"
        ]
        user_reshaped = reshape_to_feature_table(normalized_cycle, selected_features)
        elite_reshaped = reshape_to_feature_table(elite_cycles, selected_features)

        # similarities = compare_cosine_similarity_all_phases(phase_analysis, ELITE_BENCHMARK)
        overall_similarity, phases_similarity_dict = get_similarity_results(user_reshaped, elite_reshaped)
        print(f'Similarity: {overall_similarity, phases_similarity_dict}')

        # deviation_results = calculate_statistical_deviation(phase_analysis, ELITE_BENCHMARK)
        deviation_results = calculate_statistical_deviation_from_df(user_reshaped, elite_reshaped)
        print(f'deviation_results: {deviation_results}')
        dtw_distances = dtw_compare_gait_phases(user_cycle_data=normalized_cycle, elite_cycle_data=elite_cycles)
        print(f'dtw_distances: {dtw_distances}')
        autoencoder_mape_result = evaluate_models_and_collect_mape(pose_data, model_dir=model_dir)
        print(autoencoder_mape_result)

        # Generate AI feedback
        feedback = generate_ai_feedback(
            overall_similarity,
            phases_similarity_dict, 
            deviation_results, 
            dtw_distances, 
            autoencoder_mape_result, 
            language, 
            user_age, 
            user_height, 
            user_weight, 
            user_gender
        )

        print(f'feedback: {feedback}')

        
        return feedback, overall_similarity, phases_similarity_dict, normalized_cycle, elite_cycles
        
    except Exception as e:
        st.error(f"Error during processing: {str(e)}")
        return None, None, None, None, None

def main():
    # Custom CSS for better UI (Dark theme compatible)
    st.markdown("""
    <style>
    .main-header {
        text-align: center;
        padding: 2rem 0;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .stButton>button {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        padding: 0.8rem 2rem;
        font-weight: 600;
        border-radius: 10px;
        transition: all 0.3s ease;
    }
    .stButton>button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.2);
    }
    .success-message {
        background: rgba(40, 167, 69, 0.2);
        color: #28a745;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #28a745;
    }
    .feedback-container {
        background: rgba(102, 126, 234, 0.05);
        padding: 2rem;
        border-radius: 15px;
        border-left: 4px solid #667eea;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Header
    st.markdown("""
    <div class="main-header">
        <h1>🏃‍♂️ Personalized Running Posture Analysis feedback</h1>
        <p>by MediaPipe and Generative AI</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Initialize session state
    if 'analysis_complete' not in st.session_state:
        st.session_state.analysis_complete = False
    if 'video_path' not in st.session_state:
        st.session_state.video_path = None
    
    # Create two columns for better layout
    col1, col2 = st.columns([1.2, 1])
    
    with col1:
        st.markdown("### 📤 Upload Your Run")
        
        # Video file uploader
        uploaded_video = st.file_uploader(
            "",
            type=['mp4', 'avi', 'mov', 'mkv', 'wmv', 'flv'],
            help="Supported formats: MP4, AVI, MOV, MKV, WMV, FLV"
        )
        
        # Handle video upload
        if uploaded_video is not None:
            # Save uploaded video to temporary file
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
                tmp_file.write(uploaded_video.read())
                video_path = tmp_file.name
                st.session_state.video_path = video_path  # Save to session state
                
                # Show success with file info
                file_size = len(uploaded_video.getvalue()) / (1024 * 1024)  # Convert to MB
                st.markdown(f"""
                <div class="success-message">
                    <strong>✅ Video uploaded successfully!</strong><br>
                    File: {uploaded_video.name}<br>
                    Size: {file_size:.2f} MB
                </div>
                """, unsafe_allow_html=True)
        else:
            video_path = None
            st.info("💡 Upload your running video for personalized feedback")
    
    with col2:
        st.markdown("### ⚙️ Your Persona")
        
        # Compact form layout
        sub_col1, sub_col2 = st.columns(2)
        
        with sub_col1:
            # Language selection
            language = st.selectbox(
                "Result Language",
                options=["ENG", "TH"],
                format_func=lambda x: "🇬🇧 English" if x == "ENG" else "🇹🇭 ไทย"
            )
            
            # User age input
            user_age = st.number_input(
                "Age",
                min_value=1,
                max_value=120,
                value=20,
                step=1
            )
            
            # Gender selection
            user_gender = st.selectbox(
                "Gender",
                options=["male", "female"],
                format_func=lambda x: "👨 Male" if x == "male" else "👩 Female"
            )
        
        with sub_col2:
            # User height input
            user_height = st.number_input(
                "Height (cm)",
                min_value=50,
                max_value=250,
                value=180,
                step=1
            )
            
            # User weight input
            user_weight = st.number_input(
                "Weight (kg)",
                min_value=20,
                max_value=300,
                value=70,
                step=1
            )
    
    # Submit button - centered
    st.markdown("<br>", unsafe_allow_html=True)
    
    col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 1])
    with col_btn2:
        analyze_button = st.button("🔍 Analyze Gait", type="primary", use_container_width=True)
    
    if analyze_button:
        if video_path is None:
            st.error("❌ Please upload a video file before analyzing!")
        else:
            # Store values in session state
            st.session_state.language = language
            st.session_state.user_age = user_age
            st.session_state.user_height = user_height
            st.session_state.user_weight = user_weight
            st.session_state.user_gender = user_gender
            
            # Processing section - NO WHITE BOX
            st.markdown("---")
            
            # Progress tracking
            progress_placeholder = st.empty()
            status_placeholder = st.empty()
            
            # Start analysis with progress updates
            with st.spinner(""):
                # Show processing steps
                progress_placeholder.progress(0.2)
                status_placeholder.info("🎥 Extracting pose data from video...")
                
                # Simulate progress (in real app, update based on actual progress)
                import time
                time.sleep(0.5)
                
                progress_placeholder.progress(0.4)
                status_placeholder.info("🚶 Detecting gait cycles...")
                time.sleep(0.5)
                
                progress_placeholder.progress(0.6)
                status_placeholder.info("📊 Analyzing movement patterns...")
                time.sleep(0.5)
                
                progress_placeholder.progress(0.8)
                status_placeholder.info("🤖 Generating AI feedback...")
                
                # Actual processing
                feedback, overall_similarity, similarities, normalized_cycle, elite_cycles = main_processing(
                    video_path, language, user_age, user_height, user_weight, user_gender
                )
                
                progress_placeholder.progress(1.0)
                status_placeholder.success("✅ Analysis completed successfully!")
                
                # Save results to session state
                if feedback is not None:
                    st.session_state.analysis_complete = True
                    st.session_state.feedback = feedback
                    st.session_state.overall_similarity = overall_similarity
                    st.session_state.similarities = similarities
                    st.session_state.normalized_cycle = normalized_cycle
                    st.session_state.elite_cycles = elite_cycles
    
    # Show results if analysis is complete (outside of button condition)
    if st.session_state.analysis_complete:
        # Results section with tabs
        st.markdown("<br><hr><br>", unsafe_allow_html=True)
        st.markdown("## 📊 Analysis Results")
        
        # Create tabs for organized results
        tab1, tab2, tab3, tab4 = st.tabs(["💬 AI Feedback", "📈 Similarity Analysis", "📊 Feature Comparison", "🎥 Video Analysis"])
        
# แทนที่ส่วนนี้:
# with tab1:
#     st.markdown("### Running Coach AI Feedback")
#     st.markdown(st.session_state.feedback)

# เป็น:

        with tab1:
            st.markdown("### 💬 AI Running Coach Chat")
            
            # Initialize chat history in session state
            if 'chat_history' not in st.session_state:
                st.session_state.chat_history = []
                # Add initial AI feedback as first message
                if hasattr(st.session_state, 'feedback'):
                    st.session_state.chat_history.append({
                        'role': 'assistant',
                        'content': st.session_state.feedback,
                        'timestamp': datetime.now()
                    })
            
            # Display chat history
            st.markdown("#### 📋 Conversation History")
            
            # Create a container for chat messages
            chat_container = st.container()
            
            with chat_container:
                if not st.session_state.chat_history:
                    st.info("💡 Ask me anything about your running analysis!")
                else:
                    for i, message in enumerate(st.session_state.chat_history):
                        if message['role'] == 'assistant':
                            # AI message
                            with st.chat_message("assistant", avatar="🤖"):
                                if i == 0:  # First message is the original analysis
                                    st.markdown("**🏃‍♂️ Initial Gait Analysis Report**")
                                st.markdown(message['content'])
                                st.caption(f"⏰ {message['timestamp'].strftime('%H:%M')}")
                        
                        elif message['role'] == 'user':
                            # User message
                            with st.chat_message("user", avatar="👤"):
                                st.markdown(message['content'])
                                st.caption(f"⏰ {message['timestamp'].strftime('%H:%M')}")
            
            # Chat input section
            st.markdown("#### 💭 Ask Follow-up Questions")
            
            # Predefined quick questions
            st.markdown("**Quick Questions:**")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("🏋️ What exercises should I do?", use_container_width=True):
                    st.session_state.quick_question = "What specific exercises or drills should I do to improve my running form based on my analysis?"
            
            with col2:
                if st.button("⚕️ Injury prevention tips?", use_container_width=True):
                    st.session_state.quick_question = "Based on my gait analysis, what should I focus on to prevent running injuries?"
            
            with col3:
                if st.button("📈 How to track progress?", use_container_width=True):
                    st.session_state.quick_question = "How can I monitor my progress and know if my running form is improving?"
            
            # Text input for custom questions
            with st.form("chat_form", clear_on_submit=True):
                user_input = st.text_area(
                    "Ask your question:",
                    placeholder="e.g., How long will it take to see improvements? What should I focus on first?",
                    height=100,
                    key="user_question"
                )
                
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    submit = st.form_submit_button("💬 Ask Coach", use_container_width=True)
            
            # Handle quick question
            if hasattr(st.session_state, 'quick_question'):
                user_input = st.session_state.quick_question
                submit = True
                del st.session_state.quick_question
            
            # Process user input
            if submit and user_input.strip():
                # Add user message to history
                st.session_state.chat_history.append({
                    'role': 'user',
                    'content': user_input,
                    'timestamp': datetime.now()
                })
                
                # Generate AI response using existing function with user_question parameter
                with st.spinner("🤔 Coach is thinking..."):
                    ai_response = generate_ai_feedback(
                        st.session_state.overall_similarity,
                        st.session_state.similarities, 
                        getattr(st.session_state, 'deviation_results', {}),
                        getattr(st.session_state, 'dtw_distances', {}),
                        getattr(st.session_state, 'autoencoder_mape_result', None),
                        st.session_state.language,
                        st.session_state.user_age,
                        st.session_state.user_height, 
                        st.session_state.user_weight,
                        st.session_state.user_gender,
                        user_question=user_input  # เพิ่ม parameter นี้
                    )
                
                # Add AI response to history
                st.session_state.chat_history.append({
                    'role': 'assistant',
                    'content': ai_response,
                    'timestamp': datetime.now()
                })
                
                # Rerun to show new messages
                st.rerun()
        
        with tab2:
            st.markdown("### Overall and Phase Similarity")
            # Create centered column for smaller plot
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                plot_overall_and_phase_similarity(st.session_state.similarities, st.session_state.overall_similarity)
        
        with tab3:
            st.markdown("### Feature Comparison Analysis")
            
            # List of features to plot
            features = [
                'stride_width', 'center_of_mass_y', 'arm_swing_ratio',
                'leading_elbow_angle', 'trailing_elbow_angle',
                'leading_hip_angle', 'trailing_hip_angle',
                'leading_ankle_x', 'trailing_ankle_x',
                'leading_ankle_y', 'trailing_ankle_y',
                'leading_knee_angle', 'trailing_knee_angle',"trunk_lean"
            ]
            
            # Create grid layout using columns
            for i in range(0, len(features), 3):
                cols = st.columns(3)
                for j in range(3):
                    if i + j < len(features):
                        with cols[j]:
                            st.markdown(f"**{features[i+j].replace('_', ' ').title()}**")
                            plot_relative_feature_diff_bar(st.session_state.normalized_cycle, 
                                                         st.session_state.elite_cycles, 
                                                         features[i+j])
        
        with tab4:
                    st.markdown("### การวิเคราะห์วิดีโอพร้อมข้อต่อ")

                    # ตรวจสอบว่ามีการประมวลผลแล้วหรือยัง
                    if not hasattr(st.session_state, 'video_processed') or not st.session_state.video_processed:
                        
                        if st.session_state.video_path and os.path.exists(st.session_state.video_path):
                            
                            # กำหนดโฟลเดอร์ output ใน temp directory
                            output_dir = tempfile.gettempdir()
                            
                            try:
                                # แสดงสถานะ
                                st.info("🎬 กำลังเริ่มประมวลผลวิดีโอ...")
                                
                                # ประมวลผลวิดีโอ (ใช้ค่าคงที่)
                                temp_path, cycle_count = process_full_video_with_joints(
                                    st.session_state.video_path,
                                    sample_rate=1,  # ค่าคงที่
                                    show_all_joints=False  # ค่าคงที่
                                )

                                # ใช้ชื่อไฟล์คงที่
                                output_filename = "analyzed_video.mp4"
                                final_output_path = os.path.join(output_dir, output_filename)

                                # ย้ายไฟล์
                                if os.path.exists(temp_path):
                                    shutil.move(temp_path, final_output_path)
                                    
                                    # บันทึก path ใน session state
                                    st.session_state.processed_video_path = final_output_path
                                    st.session_state.cycle_count = cycle_count
                                    st.session_state.video_processed = True
                                    

                                else:
                                    st.error("❌ ไม่สามารถสร้างไฟล์วิดีโอได้")

                            except Exception as e:
                                st.error(f"❌ เกิดข้อผิดพลาด: {str(e)}")
                                
                                # แสดงข้อมูลเพิ่มเติมสำหรับ debug
                                with st.expander("🔍 ข้อมูล Debug"):
                                    st.write(f"Video path exists: {os.path.exists(st.session_state.video_path)}")
                                    st.write(f"Video path: {st.session_state.video_path}")
                                    st.write(f"Error type: {type(e).__name__}")
                                    st.write(f"Error details: {str(e)}")
                                    
                                # รีเซ็ตสถานะ
                                st.session_state.video_processed = False
                        else:
                            st.error("❌ ไม่พบไฟล์วิดีโอ กรุณาอัปโหลดวิดีโอใหม่")

                    # แสดงผลลัพธ์หากมีการประมวลผลแล้ว (จะแสดงทันทีหลังประมวลผลเสร็จ)
                    if (hasattr(st.session_state, 'video_processed') and 
                        st.session_state.video_processed and 
                        hasattr(st.session_state, 'processed_video_path')):
                        
                        if os.path.exists(st.session_state.processed_video_path):
                            
                            st.markdown("### 📊 ข้อมูลการวิเคราะห์")
                            
                            # แสดงข้อมูลเพิ่มเติม
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("รอบการเดิน/วิ่ง", f"{st.session_state.cycle_count} รอบ")
                            with col2:
                                file_size_mb = os.path.getsize(st.session_state.processed_video_path) / (1024 * 1024)
                                st.metric("ขนาดไฟล์", f"{file_size_mb:.1f} MB")
                            
                            # ปุ่มดาวน์โหลด (ชื่อไฟล์คงที่)
                            if os.path.exists(st.session_state.processed_video_path):
                                with open(st.session_state.processed_video_path, 'rb') as video_file:
                                    video_bytes = video_file.read()
                                    
                                    st.download_button(
                                        label="📥 ดาวน์โหลดวิดีโอที่วิเคราะห์แล้ว",
                                        data=video_bytes,
                                        file_name="analyzed_video.mp4",
                                        mime="video/mp4",
                                        use_container_width=True
                                    )
                                
                        else:
                            st.error("❌ ไฟล์วิดีโอหายไป")
                            # รีเซ็ตสถานะ
                            st.session_state.video_processed = False
                    
                    # แสดงคำแนะนำ
                    with st.expander("💡 เคล็ดลับการใช้งาน"):
                        st.markdown("""
                        **สำหรับผลลัพธ์ที่ดีที่สุด:**
                        - ใช้วิดีโอที่มีความชัดเจน ไม่เบลอ
                        - ถ่ายจากด้านข้าง โดยให้เห็นร่างกายทั้งตัว
                        - พื้นหลังไม่ซับซ้อน สีเรียบๆ
                        - แสงสว่างเพียงพอ
                        - ระยะห่างที่เหมาะสม ไม่ใกล้หรือไกลเกินไป
                        
                        **การประมวลผลอัตโนมัติ:**
                        - วิดีโอจะถูกประมวลผลอัตโนมัติเมื่อเปิด tab นี้ครั้งแรก
                        - หากต้องการประมวลผลใหม่ให้รีเฟรชหน้าเว็บ
                        - ดาวน์โหลดไฟล์เพื่อดูวิดีโอที่วิเคราะห์แล้ว
                        """)

if __name__ == "__main__":
    # Configure page
    st.set_page_config(
        page_title="Gait Analysis System",
        page_icon="🏃‍♂️",
        layout="wide",
        initial_sidebar_state="collapsed"
    )
    
    main()